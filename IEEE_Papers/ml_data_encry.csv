"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Privacy-Preserving Multilayer In-Band Network Telemetry and Data Analytics: For Safety, Please do Not Report Plaintext Data","X. Pan; S. Tang; S. Liu; J. Kong; X. Zhang; D. Hu; J. Qi; Z. Zhu","School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Zhongxing Telecommunication Equipment (ZTE) Corporation, Nanjing, China; Zhongxing Telecommunication Equipment (ZTE) Corporation, Nanjing, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China","Journal of Lightwave Technology","8 Oct 2020","2020","38","21","5855","5866","With the evolution of Internet infrastructure and network services, multilayer in-band network telemetry (ML-INT) and data analytics (DA) have been considered as key enabling techniques to realize real-time and fine-grained network monitoring, especially for backbone IP-over-Optical networks. However, the existing ML-INT&DA systems have privacy and security issues, because plaintext ML-INT data is reported from the data plane and gets analyzed in the control plane. In this work, we address these issues by designing a privacy-preserving ML-INT&DA system for IP-over-Optical networks. We first leverage vector homomorphic encryption (VHE) to design a lightweight encryption scheme, which overcomes the security breaches due to eavesdropping and preserves the delicate correlations buried in multi-dimensional ML-INT data. Then, we develop an effective data compression scheme to further encode the encrypted ML-INT data and make the results suitable for hash-based signature. The signature is for data certification and enables the DA in the control plane to verify the integrity of received ML-INT data. Hence, the threats from data tampering are removed. Next, we architect a deep learning (DL) model that can directly operate on encrypted ML-INT data for anomaly detection. Finally, we implement the proposed ML-INT&DA system, and experimentally demonstrate its effectiveness in a real IP over elastic optical network (IP-over-EON) testbed, whose key elements, i.e., optical line system (OLS), bandwidth-variable wavelength-selective switches (BV-WSS') and programmable data plane (PDP) switches, are all commercial products.","1558-2213","","10.1109/JLT.2020.3007491","National Natural Science Foundation of China(grant numbers:61871357,61771445,61701472); ZTE Research Fund(grant numbers:PA-HQ-20190925001J-1); Zhejiang Lab Research Fund(grant numbers:2019LE0AB01); Chinese Academy of Sciences Key Project(grant numbers:QYZDY-SSW-JSC003); Chinese Academy of Sciences(grant numbers:XDC02070300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134881","Data analytics;deep learning (dl);in-band network telemetry (int);ip over elastic optical networks (ip-over-eons);multilayer networks;privacy-preserving network monitoring;soft failures;vector homomorphic encryption (vhe)","Telemetry;Optical switches;Monitoring;Optical fiber networks;Encryption","computer network security;cryptography;data analysis;data compression;data privacy;digital signatures;Internet;IP networks;optical fibre networks;optical switches;telemetry","plaintext ML-INT data;multidimensional ML-INT data;effective data compression scheme;data certification;bandwidth-variable wavelength-selective switches;data analytics;network services;fine-grained network monitoring;privacy-preserving multilayer in-band network telemetry;Internet infrastructure;backbone IP-over-optical networks;privacy-preserving ML-INT&DA system;vector homomorphic encryption;hash-based signature;deep learning mode;IP over elastic optical network;IP-over-EON;optical line system;OLS;BV-WSS;programmable data plane switches;PDP;IP","","1","","58","IEEE","7 Jul 2020","","","IEEE","IEEE Journals"
"Privacy-Preserving Multilayer In-Band Network Telemetry and Data Analytics","X. Pan; S. Tang; Z. Zhu","School of Information Science and Technology, University of Science and Technology of China,Hefei,China; School of Information Science and Technology, University of Science and Technology of China,Hefei,China; School of Information Science and Technology, University of Science and Technology of China,Hefei,China","2020 IEEE/CIC International Conference on Communications in China (ICCC)","9 Nov 2020","2020","","","142","147","As a new paradigm for the monitoring and troubleshooting of backbone networks, the multilayer in-band network telemetry (ML-INT) with deep learning (DL) based data analytics (DA) has recently been proven to be effective on realtime visualization and fine-grained monitoring. However, the existing studies on ML-INT&DA systems have overlooked the privacy and security issues, i.e., a malicious party can apply tapping in the data reporting channels between the data and control planes to illegally obtain plaintext ML-INT data in them. In this paper, we discuss a privacy-preserving DL-based ML-INT&DA system for realizing AI-assisted network automation in backbone networks in the form of IP-over-Optical. We first show a lightweight encryption scheme based on integer vector homomorphic encryption (IVHE), which is used to encrypt plaintext ML-INT data. Then, we architect a DL model for anomaly detection, which can directly analyze the ciphertext ML-INT data. Finally, we present the implementation and experimental demonstrations of the proposed system. The privacy-preserving DL-based ML-INT&DA system is realized in a real IP over elastic optical network (IP-over-EON) testbed, and the experimental results verify the feasibility and effectiveness of our proposal.","2377-8644","978-1-7281-7327-6","10.1109/ICCC49849.2020.9238883","NSFC(grant numbers:61871357,61771445,61701472); CAS Key Project(grant numbers:QYZDY-SSW-JSC003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238883","In-band network telemetry (INT);Deep learning (DL);Integer vector homomorphic encryption (IVHE);Privacy-preserving network monitoring;Soft failures","Data analysis;Nonhomogeneous media;Data models;Encryption;Telemetry;Proposals;Monitoring","cryptography;data privacy;IP networks;neural nets;optical fibre networks;telemetry","Privacy-Preserving Multilayer In-Band Network Telemetry;backbone networks;deep learning based data analytics;fine-grained monitoring;security issues;data reporting channels;control planes;plaintext ML-INT data;AI-assisted network automation;ciphertext ML-INT data;privacy-preserving DL-based ML-INT&DA system;IP over elastic optical network testbed;integer vector homomorphic encryption","","1","","45","","9 Nov 2020","","","IEEE","IEEE Conferences"
"Multilayer Network Monitoring and Data Analytics over Encrypted Telemetry Data","X. Pan; S. Tang; Z. Zhu","University of Science and Technology of China,School of Information Science and Technology,Hefei,China; University of Science and Technology of China,School of Information Science and Technology,Hefei,China; University of Science and Technology of China,School of Information Science and Technology,Hefei,China","2020 IEEE 20th International Conference on Communication Technology (ICCT)","24 Dec 2020","2020","","","1577","1581","Multilayer in-band network telemetry (ML-INT) and data analytics (DA) is the key techniques for monitoring and troubleshooting backbone networks, since they obtain real-time and fine-grained telemetry data about the optical and IP layers and facilitate artificial intelligence (AI) assisted network automation. Despite their success, there are still privacy and security issues to address for realizing a practical ML-INT&DA system. This is because a malicious party can obtain plaintext telemetry data illegally by tapping the data reporting channels between the control and data planes, derive sensitive information about the network, and launch various attacks accordingly. In this paper, we propose to realize multilayer network monitoring and data analytics over encrypted telemetry data and demonstrate a privacy-preserving ML-INT&DA system to address the aforementioned issues. More specifically, we first utilize the vector homomorphic encryption (VHE) to encrypt ML-INT data, i.e., the threats from data tapping can removed, and then architect a deep learning (DL) model for anomaly detection, which can directly operate on the encrypted data. We implement and experimentally demonstrate the feasibility of the proposed system in a real IP over elastic optical network (IP-over-EON) testbed, and the results confirm the effectiveness of our proposal.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295879","In-band network telemetry (INT);Deep learning (DL);Vector homomorphic encryption (VHE)","Optical switches;Encryption;Signal to noise ratio;Optical noise;Monitoring;Telemetry;Cryptography","computer network security;cryptography;data analysis;data privacy;deep learning (artificial intelligence);IP networks;optical fibre networks;optical fibre telemetry;telecommunication computing","encrypted telemetry data;data analytics;fine-grained telemetry data;artificial intelligence assisted network automation;plaintext telemetry data;multilayer network monitoring;multilayer in-band network telemetry;backbone networks;optical layers;IP layers;AI assisted network automation;ML-INT&DA system;privacy-preserving ML-INT&DA system;vector homomorphic encryption;VHE;deep learning model;anomaly detection;IP over elastic optical network;IP-over-EON","","","","42","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Data Leakage Prevention for Data in Transit using Artificial Intelligence and Encryption Techniques","M. Ghouse; M. J. Nene; V. C.","DM, Network and Cyber Security, Bharat Electronics Limited,Bangalore,India; Defense Institute of Advanced Technology,Dept. of Computer Science and Engineering,Pune,India; MRS, Cyber Security Central Research Laboratory, BEL,Bangalore,India","2019 International Conference on Advances in Computing, Communication and Control (ICAC3)","16 Mar 2020","2019","","","1","6","Data leakage in an organization is a very important concern that leads to the ex-filtration of data, The work in this paper addresses a novel concept for prevention of data leakage for data in transit. The text under consideration is classified to confidential or non-confidential category based on the content and context using Machine Learning technique. Subsequent action for encryption is performed on the confidential data and then transmitted from the Intranet domain to Internet domain ensuring that the data is not compromised to unauthorized users. In addition, normal transactional data which is nonconfidential in nature is not prevented from transmitting and is easily accessible by a third party. Encryption is applied only to selected data and not the entire data in transit, ensuring that the hardware resources are efficiently utilized. An adversary can simply compose an e-mail with the organization's confidential information as the body of the mail, in such scenarios our method will classify the e-mail content and will encrypt the data so that the data is not revealed to an outsider.","","978-1-7281-2386-8","10.1109/ICAC347590.2019.9036839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9036839","Text Classification;Data Leakage Prevention (DLP);Encryption;Gateway;Intranet;Internet;Decryption;Artificial Intelligence (AI);Machine Learning (ML);Trusted Platform Module (TPM)","","cryptography;data protection;electronic mail;Internet;intranets;learning (artificial intelligence)","data leakage prevention;encryption;nonconfidential category;confidential data;normal transactional data;confidential information;ex-filtration;artificial intelligence;machine learning technique;Intranet domain;Internet domain","","4","","18","","16 Mar 2020","","","IEEE","IEEE Conferences"
"Privacy-Preserving Scoring of Tree Ensembles: A Novel Framework for AI in Healthcare","K. Fritchman; K. Saminathan; R. Dowsley; T. Hughes; M. De Cock; A. Nascimento; A. Teredesai","Institute of Technology, University of Washington, Tacoma, Washington, USA; Institute of Technology, University of Washington, Tacoma, Washington, USA; Dept. of Computer Science, Aarhus University, Aarhus, Denmark; KenSci, Seattle, Washington, USA; Institute of Technology, University of Washington, Tacoma, Washington, USA; Institute of Technology, University of Washington, Tacoma, Washington, USA; Institute of Technology, University of Washington, Tacoma, Washington, USA","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","2413","2422","Machine Learning (ML) techniques now impact a wide variety of domains. Highly regulated industries such as healthcare and finance have stringent compliance and data governance policies around data sharing. Advances in secure multiparty computation (SMC) for privacy-preserving machine learning (PPML) can help transform these regulated industries by allowing ML computations over encrypted data with personally identifiable information (PII). Yet very little of SMC-based PPML has been put into practice so far. In this paper we present the very first framework for privacy-preserving classification of tree ensembles with application in healthcare. We first describe the underlying cryptographic protocols that enable a healthcare organization to send encrypted data securely to a ML scoring service and obtain encrypted class labels without the scoring service actually seeing that input in the clear. We then describe the deployment challenges we solved to integrate these protocols in a cloud based scalable risk-prediction platform with multiple ML models for healthcare AI. Included are system internals, and evaluations of our deployment for supporting physicians to drive better clinical outcomes in an accurate, scalable, and provably secure manner. To the best of our knowledge, this is the first such applied framework with SMC-based privacy-preserving machine learning for healthcare.","","978-1-5386-5035-6","10.1109/BigData.2018.8622627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622627","privacy-preserving machine learning;secure multiparty computation;encryption;healthcare;random forest;boosted decision trees","Protocols;Medical services;Cryptography;Machine learning;Data privacy;Privacy;Decision trees","cloud computing;cryptographic protocols;data privacy;health care;learning (artificial intelligence);medical computing;pattern classification","privacy-preserving scoring;tree ensembles;data governance policies;data sharing;secure multiparty computation;encrypted data;personally identifiable information;SMC-based PPML;privacy-preserving classification;healthcare organization;ML scoring service;multiple ML models;healthcare AI;SMC-based privacy-preserving machine;ML techniques;cryptographic protocols;cloud based scalable risk-prediction platform;SMC-based privacy-preserving machine learning","","3","","39","","24 Jan 2019","","","IEEE","IEEE Conferences"
"The Multi Layer Auto Encoder Neural Network (ML-AENN) for Encryption and Decryption of Text Message","A. F. O. Gaffar; A. B. W. Putra; R. Malani","Politeknik Negeri Samarinda,Department of Information Technology,East Kalimantan,Indonesia; Politeknik Negeri Samarinda,Department of Information Technology,East Kalimantan,Indonesia; Politeknik Negeri Samarinda,Department of Information Technology,East Kalimantan,Indonesia","2019 5th International Conference on Science in Information Technology (ICSITech)","10 Feb 2020","2019","","","128","133","Efficient key generation techniques require highly secure cryptosystems. The traditional key generation technique is very systematic that it is easy to attack. The Deep Learning algorithm is one of the research paths into the automated extraction of complex data representations (features) at a high level of abstraction. Auto Encoder Neural Network (AENN), one of the deep learning's architectures, play an essential role in unsupervised learning in deep architecture for learning transfer and other tasks. The AENN are simple learning networks that aim to convert inputs into outputs with the least amount of distortion. This study proposes the Deep Learning approach for text message encryption and decryption by using the Multi-Layer AENN where the outputs of each of the deepest layer as the secret-key generator and hash value generator. The result of this research showed that the proposed method has a high degree of confidentiality because each training always produces a different secret key. Furthermore, the tampered data/information can be seen from the presence of different hash values that occur.","","978-1-7281-2380-6","10.1109/ICSITech46713.2019.8987462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987462","encryption;decryption;secret key;AENN;confidentiality","","encoding;neural nets;private key cryptography;text analysis;unsupervised learning","automated extraction;complex data representations;unsupervised learning;text message encryption;secret-key generator;value generator;ML-AENN;key generation techniques;highly secure cryptosystems;deep learning algorithm;research paths;multilayer auto encoder neural network;text message decryption;multilayer AENN","","1","","17","","10 Feb 2020","","","IEEE","IEEE Conferences"
"A Comparative Analysis of Machine Learning Models developed from Homomorphic Encryption based RSA and Paillier algorithm","H. J. Kiratsata; M. Panchal","GTU-Graduate School of Engineering and Technology,Cyber security department,Ahmedabad,India; GTU-Graduate School of Engineering and Technology,Cyber security department,Ahmedabad,India","2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)","26 May 2021","2021","","","1458","1465","Nowadays, the use of Auto ML for development of machine learning (ML) models is increasing day by day. In which users need to upload their dataset to develop machine learning models. Where security of user's data is a very big problem. Which can be solved using Homomorphic encryption. In this work, first the spiderman correlation of the machine learning models developed using encrypted dataset is compared with each other. In which the algorithms used to encrypt dataset are Homomorphic Encryption (HE) based Rivest Shamir Adleman (RSA) and Paillier algorithm. Where the homomorphic encryption based Rivest Shamir Adleman (RSA) is a multiplicative operation and the HE-based Pailler supports additive operations. These algorithms are used to encrypt data and store it on cloud servers. An in-house key generator is developed to generate keys for HE-based RSA algorithm and used this algorithm to encrypt data. Then a comparison between the time taken by these algorithms to encrypt the data and develop the machine learning model using Azure auto Machine Learning is done where the HE-based RSA algorithm is winner.","","978-1-6654-1272-8","10.1109/ICICCS51141.2021.9432348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432348","Partially Homomorphic Encryption;Machine Learning;RSA;Paillier;Ensemble method;Data Privacy;Cryptography;Homomorphic Encryption","Analytical models;Machine learning algorithms;Correlation;Computational modeling;Machine learning;Control systems;Data models","cryptography;learning (artificial intelligence)","machine learning models;homomorphic encryption;HE-based RSA algorithm;Azure automachine learning;Paillier algorithm;spiderman correlation;Rivest Shamir Adleman algorithm;in-house key generator;additive operations;multiplicative operation","","","","27","","26 May 2021","","","IEEE","IEEE Conferences"
"On Fully Homomorphic Encryption for Privacy-Preserving Deep Learning","N. J. Hernandez Marcano; M. Moller; S. Hansen; R. H. Jacobsen",Aarhus University; Aarhus University; Aarhus University; Aarhus University,"2019 IEEE Globecom Workshops (GC Wkshps)","5 Mar 2020","2019","","","1","6","Given the rise of Machine Learning (ML) applications using sensitive private data, we present an implementation of Fully Homomorphic Encryption (FHE) with Convolutional Neural Networks (CNNs) for privacy-preserving Deep Learning (DL). This permits to utilize DL image recognition algorithms without compromising personal data of served customers, e.g medical images. The combination of FHE and CNN is accomplished by using logic circuits, which enable to conduct deep learning algorithms on ciphertext instead of plaintext. We provide a set of practical measurements from an implementation on the number of logic circuit operations required to carry out privacy-preserving ML. The results are function of the numerical representation and security parameters. Our results indicate that the protection of customer data is a trade-off between the required level of security, prediction capability and computational complexity. Thus, we reach full correct classification with 6 bits in the fractional part, and evaluate the time costs associated with our circuits as a function of its security parameters.","","978-1-7281-0960-2","10.1109/GCWkshps45667.2019.9024625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024625","","Encryption;Machine learning;Logic circuits;Logic gates;Feature extraction","computational complexity;convolutional neural nets;cryptography;data protection;image classification;learning (artificial intelligence);logic circuits","CNN;security parameters;computational complexity;convolutional neural networks;personal data;DL image recognition algorithms;sensitive private data;privacy-preserving deep learning;fully homomorphic encryption;customer data protection;privacy-preserving ML;logic circuit operations;deep learning algorithms;logic circuits;FHE;word length 6.0 bit","","1","","17","","5 Mar 2020","","","IEEE","IEEE Conferences"
"sec-cs: Getting the Most out of Untrusted Cloud Storage","D. Leibenger; C. Sorge","CISPA, Saarland Univ., Saarbrucken, Germany; CISPA, Saarland Univ., Saarbrucken, Germany","2017 IEEE 42nd Conference on Local Computer Networks (LCN)","16 Nov 2017","2017","","","623","631","We present sec-cs, a hash-table-like data structure for contents on untrusted storage that is provably secure and storage-efficient. We achieve authenticity and confidentiality with zero storage overhead using deterministic authenticated encryption. State-of-the-art data deduplication approaches prevent redundant storage of shared parts of different contents irrespective of whether relationships between contents are known a priori. Instead of just adapting existing approaches, we introduce novel (multi-level) chunking strategies, ML-SC and ML-CDC, which are significantly more storage-efficient than existing approaches in presence of high redundancy. We prove sec-cs's security, publish an implementation, and present evaluation results indicating suitability for, e.g., future backup systems that should preserve many versions of files on little available storage.","0742-1303","978-1-5090-6523-3","10.1109/LCN.2017.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109424","Cloud Storage;Security;Data Deduplication;Data Structures;Storage Efficiency","Cloud computing;Vegetation;Redundancy;Data structures;Cryptography;Metadata","cloud computing;cryptography;data structures;storage management;trusted computing","sec-cs;untrusted cloud storage;hash-table-like data structure;untrusted storage;authenticity;confidentiality;deterministic authenticated encryption;ML-CDC;data deduplication;storage redundancy;multilevel chunking strategies;ML-SC","","2","","45","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Secure and Efficient <italic>k</italic> NN Classification for Industrial Internet of Things","H. Yang; S. Liang; J. Ni; H. Li; X. S. Shen","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, Queen’s University, Kingston, Canada; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","10945","10954","The k-nearest neighbors (kNN) classification has been widely used for defective product identification and anomaly detection in the Industrial Internet of Things (IIoT). In this article, we propose a secure and efficient distributed kNN classification algorithm (SEED-kNN) to prevent information and control flow exposure while supporting large-scale data classification on distributed servers. Specifically, we first design a secure and efficient vector homomorphic encryption (VHE) scheme by constructing a key-switching matrix and a noise matrix for data encryption. Based on the designed VHE, SEEDkNN is proposed to efficiently achieve the confidentiality of data flow, kNN query, and class label, while enabling homomorphic operations on the encrypted data. Moreover, by leveraging the Map/Reduce architecture, SEED-kNN enables the kNN classification over the large-scale encrypted data on distributed servers for industrial control systems. Finally, we demonstrate that SEEDkNN achieves semantic security and high classification accuracy, and is applicable in IIoT due to its high efficiency.","2327-4662","","10.1109/JIOT.2020.2992349","National Key Research and Development Program of China(grant numbers:2017YFB0802300,2017YFB0802000,2017YFB0802003); National Natural Science Foundation of China(grant numbers:U1633114); Sichuan Science and Technology Program(grant numbers:2018GZ0202); State Key Laboratory of Cryptography(grant numbers:MMKFKT201912); Research Grant of the Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086811","Big data;Industrial Internet of Things (IIoT);intelligent systems;machine learning (ML);security and privacy","Servers;Industrial control;Cryptography;Cloud computing;Distributed databases","cryptography;data handling;data privacy;industrial control;Internet of Things;parallel processing;pattern classification;production engineering computing;query processing","data flow;kNN query;SEED-kNN;large-scale encrypted data;distributed servers;industrial control systems;semantic security;IIoT;k-nearest neighbors classification;anomaly detection;large-scale data classification;data encryption;VHE;vector homomorphic encryption;class label;efficiency K-NN classification;secure K-NN classification;MapReduce architecture","","2","","38","IEEE","5 May 2020","","","IEEE","IEEE Journals"
"AHEC: End-to-end Compiler Framework for Privacy-preserving Machine Learning Acceleration","H. Chen; R. Cammarota; F. Valencia; F. Regazzoni; F. Koushanfar","UC San Diego,San Diego,USA; Intel Lab,San Diego,USA; ALaRI,Switzerland; ALaRI,Switzerland; UC San Diego,San Diego,USA","2020 57th ACM/IEEE Design Automation Conference (DAC)","9 Oct 2020","2020","","","1","6","Privacy-preserving machine learning (PPML) is driven by the emerging adoption of Machine Learning as a Service (MLaaS). In a typical MLaaS system, the end-user sends his personal data to the service provider and receives the corresponding prediction output. However, such interaction raises severe privacy concerns about both the user's proprietary data and the server's ML model. PPML integrates cryptographic primitives such as Multi-Party Computation (MPC) and/or Homomorphic Encryption (HE) into ML services to resolve the privacy issue. However, existing PPML solutions have not been widely deployed in practice since: (i) Privacy protection comes at the cost of additional computation and/or communication overhead; (ii) Adapting PPML to different front-end frameworks and back-end hardware incurs prohibitive engineering cost.We propose AHEC, the first automated, end-to-end HE compiler for efficient PPML inference. Leveraging the capability of Domain Specific Languages (DSLs), AHEC enables automated generation and optimization of HE kernels across diverse types of hardware platforms and ML frameworks. We perform extensive experiments to investigate the performance of AHEC from different abstraction levels: HE operations, HE-based ML kernels, and neural network layers. Empirical results corroborate that AHEC achieves superior runtime reduction compared to the state-of-the-art solutions built from static HE libraries.","0738-100X","978-1-7281-1085-1","10.1109/DAC18072.2020.9218508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218508","","Hardware;Optimization;Kernel;Machine learning;Encryption;DSL","cryptography;data mining;data privacy;learning (artificial intelligence);program compilers;specification languages","AHEC;end-to-end compiler framework;privacy-preserving machine learning;end-user;personal data;service provider;prediction output;severe privacy concerns;cryptographic primitives;multiparty computation;homomorphic encryption;ML services;privacy issue;PPML solutions;Privacy protection;additional computation;front-end frameworks;back-end hardware;engineering cost;efficient PPML inference;ML frameworks;HE-based ML kernels;MLaaS system","","","","15","","9 Oct 2020","","","IEEE","IEEE Conferences"
"PlaidML-HE: Acceleration of Deep Learning Kernels to Compute on Encrypted Data","H. Chen; R. Cammarota; F. Valencia; F. Regazzoni","Intel AI Privacy and Security Research, USA; Intel AI Privacy and Security Research, USA; Advanced Learning and Research Institute, Switzerland; Advanced Learning and Research Institute, Switzerland","2019 IEEE 37th International Conference on Computer Design (ICCD)","10 Feb 2020","2019","","","333","336","Machine Learning as a Service (MLaaS) is becoming a popular practice where Service Consumers, e.g., end-users, send their data to a ML Service and receive the prediction outputs. However, the emerging usage of MLaaS has raised severe privacy concerns about users' proprietary data. PrivacyPreserving Machine Learning (PPML) techniques aim to incorporate cryptographic primitives such as Homomorphic Encryption (HE) and Multi-Party Computation (MPC) into ML services to address privacy concerns from a technology standpoint. Existing PPML solutions have not been widely adopted in practice due to their assumed high overhead and integration difficulty within various ML front-end frameworks as well as hardware backends. In this work, we propose PlaidML-HE, the first end-toend HE compiler for PPML inference. Leveraging the capability of Domain-Specific Languages, PlaidML-HE enables automated generation of HE kernels across diverse types of devices. We evaluate the performance of PlaidML-HE on different ML kernels and demonstrate that PlaidML-HE greatly reduces the overhead of the HE primitive compared to the existing implementations.","2576-6996","978-1-5386-6648-7","10.1109/ICCD46524.2019.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8988676","Machine Learning;Privacy;Homomorphic Encryption;Compiler","","cryptography;data privacy;inference mechanisms;learning (artificial intelligence)","ML front-end frameworks;PPML inference;PlaidML-HE;deep learning kernels;encrypted data;MLaaS;ML Service;privacy-preserving machine learning;cryptographic primitives;ML kernels;machine learning as a service","","1","","12","","10 Feb 2020","","","IEEE","IEEE Conferences"
"Graph Neural Networks for Prevention of Leakage of Secret Data","M. Ghouse; M. J. Nene","DM, Network and Cyber Security, Bharat Electronics Limited,Bengaluru,India; Defense Institute of Advanced Technology,Dept. of Computer Science and Engineering,Pune,India","2020 5th International Conference on Communication and Electronics Systems (ICCES)","10 Jul 2020","2020","","","994","999","The study presents the design and development of security solution pertaining to prevention of leakage of secret data that is in transit (DIT) to be deployed in a Network Gateway, the Gateway is the link connecting the Trusted Network with the Un-trusted Network. The entire solution includes, tasks such as classification of data flowing in the network, followed by the confinement of the identified data, the confinement of the identified data is done either by tagging the data or by means of encryption, however the later form is employed to achieve confinement of classified data under secret category thereby achieving confidentiality of the same. GNN is used for achieving the categorization function and the results are found to be satisfying with less processing time. The dataset that is used is the publicly available dataset and is available in its labeled format. The final deployment will however be based on the datasets that is available to meet a particular requirement of an Organization/Institution. Any organization can prepare a customized dataset suiting its requirements and train the model. The model can then be used for meeting the DLP requirement.","","978-1-7281-5371-1","10.1109/ICCES48766.2020.9137957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137957","Classification;Graph Neural Networks (GNN);Advanced Encryption Standard (AES);Artificial Intelligence (AI);Data in Rest (DiT);Machine Learning (ML);Data Leakage Prevention (DLP)","","computer network security;cryptography;graph theory;internetworking;neural nets;pattern classification","DIT;GNN;publicly available dataset;secret category;classified data;identified data;Un-trusted Network;Network Gateway;security solution;secret data;graph neural networks","","","","26","","10 Jul 2020","","","IEEE","IEEE Conferences"
"A Machine Learning Based Attack in UAV Communication Networks","X. Chen; Y. Chen",National Central University; National Central University,"2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall)","7 Nov 2019","2019","","","1","2","With the advantages of agility and mobility, unmanned aerial vehicles (UAVs) have been widely applied for various civil and military missions. To dynamically control and monitor UAV, it is necessary to broadcast their location information. However, flying in the aerial environment and the fixed operation location also make UAV communications more vulnerable to privacy attacks. In this paper, we present the machine learning (ML)-based attack of UAV-based wireless networks when an attacker can obtain both plaintext and ciphertext. The collected plaintext-ciphertext pairs can be used to train an ML classifier which can help decrypt the UAV messages. By simulations, we show that a simple neural network (NN) can decrypt UAV location data with high probability. Finally, we conclude the work and present a network coding based encryption scheme as our future research direction.","2577-2465","978-1-7281-1220-6","10.1109/VTCFall.2019.8891199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891199","","Unmanned aerial vehicles;Artificial neural networks;Machine learning;Wireless communication;Encryption;Communication system security","autonomous aerial vehicles;control engineering computing;cryptography;data privacy;learning (artificial intelligence);mobility management (mobile radio);multi-robot systems;neural nets;probability","UAV communication networks;mobility;unmanned aerial vehicles;civil missions;military missions;location information;aerial environment;operation location;privacy attacks;machine learning-based attack;UAV-based wireless networks;plaintext-ciphertext pairs;ML classifier;UAV messages;neural network;UAV location data;network coding based encryption scheme;probability","","2","","4","","7 Nov 2019","","","IEEE","IEEE Conferences"
"Encrypted Traffic Classification Based ML for Identifying Different Social Media Applications","F. Al-Obaidy; S. Momtahen; M. F. Hossain; F. Mohammadi","Department of Electrical, Computer, and Biomedical Engineering, Ryerson University, Toronto, Canada; Department of Electrical, Computer, and Biomedical Engineering, Ryerson University, Toronto, Canada; Department of Electrical, Computer, and Biomedical Engineering, Ryerson University, Toronto, Canada; Department of Electrical, Computer, and Biomedical Engineering, Ryerson University, Toronto, Canada","2019 IEEE Canadian Conference of Electrical and Computer Engineering (CCECE)","11 Oct 2019","2019","","","1","5","Increasing the deployment of encryption in network protocols and applications poses a challenge for traditional traffic classification approaches. Social media applications such as Skype, WhatsApp, Facebook, YouTube etc. as popular representatives of encrypted traffics have attracted big attention to communication and entertainment. Therefore, the accurate identification of them within encrypted traffic has become a big issue and a hot topic to explore them in detail. In this context, Machine Learning (ML) approaches have shown promise in this area especially for detecting and classifying the encrypted traffic data. Therefore, this work is concentrated on the challenges and has explored the ability to use ML algorithms for social media classification from traffic traces and provides a developed solution, which is able to identify the social media sub-class.","2576-7046","978-1-7281-0319-8","10.1109/CCECE.2019.8861934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861934","Internet messaging applications;Machine learning Classification;Social media applications;Encrypted Traffic.","Classification algorithms;Cryptography;Feature extraction;Protocols;Facebook;IP networks","cryptographic protocols;social networking (online);telecommunication traffic","encrypted traffic classification;network protocols;traffic classification;machine learning;encrypted traffic data;ML algorithms;social media classification;social media sub-class","","5","","13","","11 Oct 2019","","","IEEE","IEEE Conferences"
"Secured Health Using Machine Learning Adoption In Blockchain","P. Tamijeselvy; R. Navanitha; M. Kesavananthini; G. Rohini","Sri Krishna College of Technology,Department of CSE,Coimbatore,India; Sri Krishna College of Technology,Department of CSE,Coimbatore,India; Sri Krishna College of Technology,Department of CSE,Coimbatore,India; Sri Krishna College of Technology,Department of CSE,Coimbatore,India","2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)","3 Jun 2021","2021","1","","1007","1012","As a promising candidate for the creation of internet offers Block chain is growing. A decentralized, secure and auditable way to alter and authenticate data by transactions is kilometers away, involving a trustworthy third celebration. As a result, fitness treatment domain was newly combined with block chain technologies. The BT decentralized database illustrates stability and privacy. It also guarantees that figures are protected and valid by the consensus process. Nevertheless, modern security issues, including big threats and double spending, are rising. Facts are encrypted in sophisticated encryption for handling the above problems Collection of guidelines for standards (AES). Analyzing these facts raises the value of computer education (ML). ML provides the rational number of records for making precise decisions. In order to improve the precision of effects, knowledge reliability and their sharing are very important in ML. The synthesis of these two methods (ML and BT) may have very special implications. On this text, we present a detailed review of ML adoption to make clever applications primarily BT-based additionally vulnerable to attacks. Various traditional ML methods exist, for example, support Vector Machines (SVM), clustering, bagging and the creation of (DL) information. Includes CNN and Long Speed Time Reminiscence (LSTM) can be used to evaluate attacks on a block chain based network. If it wishes to be calm, medium happy, small healthy material, we are using naive bayes algorithms for classifying fitness data.","2575-7288","978-1-6654-0521-8","10.1109/ICACCS51430.2021.9441967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441967","Block chain;healthcare;machine learning;naive bayes;AES","Machine learning algorithms;Stability criteria;Support vector machine classification;Blockchain;Machine learning;Naive Bayes methods;Encryption","Bayes methods;blockchains;cryptography;data privacy;Internet;learning (artificial intelligence);pattern classification;support vector machines","fitness data;block chain based network;support vector machines;traditional ML methods;ML adoption;special implications;knowledge reliability;precise decisions;computer education;sophisticated encryption;double spending;big threats;modern security issues;consensus process;privacy;stability;block chain technologies;fitness treatment domain;trustworthy third celebration;internet offers Block chain;blockchain;machine learning adoption;secured health","","","","18","","3 Jun 2021","","","IEEE","IEEE Conferences"
"Privacy-Preserving Machine Learning Training in IoT Aggregation Scenarios","L. Zhu; X. Tang; M. Shen; F. Gao; J. Zhang; X. Du","School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; Zhejiang Lab Research Center for Cyber-Physical-Social System, Zhejiang Lab, Hangzhou, China; School of Cyberspace Security, Beijing Institute of Technology, Beijing, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Internet of Things Journal","26 Jul 2021","2021","8","15","12106","12118","In developing smart city, the growing popularity of machine learning (ML) that appreciates high-quality training data sets generated from diverse Internet-of-Things (IoT) devices raises natural questions about the privacy guarantees that can be provided in such settings. Privacy-preserving ML training in an aggregation scenario enables a model demander to securely train ML models with the sensitive IoT data gathered from IoT devices. The existing solutions are generally server aided, cannot deal with the collusion threat between the servers or between the servers and data owners, and do not match the delicate environments of IoT. We propose a privacy-preserving ML training framework named <monospace>Heda</monospace> that consists of a library of building blocks based on partial homomorphic encryption, which enables constructing multiple privacy-preserving ML training protocols for the aggregation scenario without the assistance of untrusted servers, and defending the security under collusion situations. Rigorous security analysis demonstrates the proposed protocols can protect the privacy of each participant in the honest-but-curious model and guarantee the security under most collusion situations. Extensive experiments validate the efficiency of <monospace>Heda</monospace>, which achieves privacy-preserving ML training without losing the model accuracy.","2327-4662","","10.1109/JIOT.2021.3060764","National Key Research and Development Program of China(grant numbers:2020YFB1006101); Beijing Nova Program(grant numbers:Z201100006820006); NSFC Projects(grant numbers:61972039,61872041); Beijing Natural Science Foundation(grant numbers:4192050); Open Research Projects of Zhejiang Lab(grant numbers:2020AA3AB04); Ministry of Education - China Mobile Research Fund Project(grant numbers:MCM20180401); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359659","Homomorphic encryption;Internet-of-Things (IoT) data;machine learning (ML);modular sequential composition;secure two-party computation","Training;Data models;Computational modeling;Encryption;Protocols;Servers;Collaboration","","","","","","56","IEEE","19 Feb 2021","","","IEEE","IEEE Journals"
"To Share or Not to Share? How Exploitation of Context Data Can Improve In-Network QoE Monitoring of Encrypted YouTube Streams","I. Orsolic; L. Skorin-Kapov; T. Hoßfeld","Faculty of Electrical Engineering and Computing, Univ. of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, Univ. of Zagreb, Zagreb, Croatia; Institute of Computer Science, Univ. of Würzburg, Würzburg, Germany","2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)","24 Jun 2019","2019","","","1","3","With the widespread use of encryption in Over the Top (OTT) traffic, Internet Service Providers (ISPs) for the most part lack insights into application performance, as well as into Quality of Experience (QoE) perceived by end users. Addressing challenges related to encryption, ISPs are looking into machine learning (ML) based solutions that can detect application performance solely from statistical properties of the traffic. On the other hand, OTT service providers are not willing to share service performance and content-related information with ISPs. While related work on OTT-ISP collaboration scenarios has addressed architectural aspects, business models, and to a certain extent incentives for sharing data, the focus of this paper is on the exchanged data itself. We investigate to what extent the performance of in-network ML-based QoE estimation models for HTTP adaptive video streaming could be improved with the availability of certain context data provided by OTT providers. We motivate OTT-ISP collaboration through more accurate in-network QoE monitoring and potential improvement of user experience, which is of interest to both sides.","2472-7814","978-1-5386-8212-8","10.1109/QoMEX.2019.8743167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8743167","","Quality of experience;Bit rate;YouTube;Over-the-top media services;Encoding;Data models","computer network reliability;cryptography;estimation theory;Internet;learning (artificial intelligence);social networking (online);statistical analysis;telecommunication traffic;video streaming","machine learning based solutions;statistical properties;OTT service providers;content-related information;OTT-ISP collaboration scenarios;in-network ML-based QoE estimation models;HTTP adaptive video streaming;in-network QoE monitoring;OTT traffic;Internet service providers;ISP;data exchange;encrypted YouTube streaming;over the top traffic;quality of experience","","2","","12","","24 Jun 2019","","","IEEE","IEEE Conferences"
"An Efficient and Privacy-Preserving Outsourced Support Vector Machine Training for Internet of Medical Things","J. Wang; L. Wu; H. Wang; K. -K. R. Choo; D. He","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, College of Computer, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, TX, USA; Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China","IEEE Internet of Things Journal","22 Dec 2020","2021","8","1","458","473","As the use of machine learning in the Internet-of-Medical Things (IoMT) settings increases, so do the data privacy concerns. Therefore, in this article, we propose an efficient privacy-preserving outsourced support vector machine scheme (EPoSVM), designed for IoMT deployment. To securely train the support vector machine (SVM), we design eight secure computation protocols to allow the cloud server to efficiently execute basic integer and floating-point computations. The proposed scheme protects training data privacy and guarantees the security of the trained SVM model. The security analysis proves that our proposed protocols and EPoSVM satisfy both security and privacy protection requirements. Findings from the performance evaluation using two real-world disease data sets also demonstrate the efficiency and effectiveness of EPoSVM in achieving the same classification accuracy as a general SVM.","2327-4662","","10.1109/JIOT.2020.3004231","National Key Research and Development Program of China(grant numbers:2018YFC1604000); National Natural Science Foundation of China(grant numbers:61772377,61932016,61972294,61941116,61672257,91746206); Natural Science Foundation of Hubei Province of China(grant numbers:2017CFA007); Science and Technology Planning Project of ShenZhen(grant numbers:JCYJ20170818112550194); Major Science Research Project of Jiangsu Provincial Education Department(grant numbers:19KJA310010); Open Foundation of the State Key Laboratory of Information Security of China(grant numbers:2020-MS-01); Cloud Technology Endowed Professorship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123359","Internet of Medical Things (IoMT);machine learning;multiple keys;outsourced support vector machine (SVM);privacy-preserving machine learning (ML)","Support vector machines;Training;Protocols;Data privacy;Encryption","cloud computing;data privacy;diseases;learning (artificial intelligence);outsourcing;support vector machines","EPoSVM;machine learning;Internet-of-Medical Things;settings increases;data privacy concerns;efficient privacy-preserving outsourced support vector machine scheme;IoMT deployment;computation protocols;floating-point computations;training data privacy;trained SVM model;security analysis;privacy protection requirements;real-world disease data sets","","1","","48","IEEE","23 Jun 2020","","","IEEE","IEEE Journals"
"Traffic Classification of QoS Types Based on Machine Learning Combined with IP Query and Deep Packet Inspection","Y. -F. Huang; C. -M. Chung; C. -B. Lin; Y. -B. Peng; S. -H. Liu; H. Chen","Chaoyang University of Technology,Dept. of Dept. of Information and Communication Engineering,Taichung,Taiwan; Chaoyang University of Technology,Dept. of Information and Communication Engineering,Taichung,Taiwan; Chaoyang University of Technology,Dept. of Information and Communication Engineering,Taichung,Taiwan; Chaoyang University of Technology,Dept. of Information and Communication Engineering,Taichung,Taiwan; Chaoyang University of Technology,Dept. of Computer Science and Information Engineering,Taichung,Taiwan; Chaoyang University of Technology,Dept. of Computer Science and Information Engineering,Taichung,Taiwan","2020 14th International Conference on Signal Processing and Communication Systems (ICSPCS)","4 Jan 2021","2020","","","1","4","Due to many network services using encryption protocols, it poses a massive challenge to accurately identify traffic and provide quality of service (QoS). Although deep packet inspection (DPI) technology can identify most traffic, there are still many disadvantages to identifying encrypted traffic. In this paper, we apply the IP (Internet Protocol) autonomous system information query with machine learning (ML) and deep packet detection technology for traffic identification. By combining these methods, it can quickly provide good QoS for different types of encrypted traffic. The experimental results show that different encrypted traffic can be effectively identified. The services with different QoS requirements can be effectively identified even if they use the same protocol.","","978-1-7281-9972-6","10.1109/ICSPCS50536.2020.9310061","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310061","Machine learning (ML);Quality of service (QoS);Traffic Identification;Deep packet inspection (DPI)","Machine learning;IP networks;Protocols;Training;Quality of service;Data models;Streaming media","IP networks;learning (artificial intelligence);quality of service;telecommunication traffic","Internet Protocol;deep packet detection technology;encrypted traffic classification;QoS;quality of service;encryption protocols;deep packet inspection technology;IP autonomous system information query;DPI technology;ML;machine learning","","","","14","","4 Jan 2021","","","IEEE","IEEE Conferences"
"Integrating Machine Learning with Blockchain to Ensure Data Privacy","S. S. Singhar; D. Jena; S. Sharma","IIIT,Bhubaneswar,India,751003; IIIT,Bhubaneswar,India,751003; IIIT,Bhubaneswar,India,751003","2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","15 Oct 2020","2020","","","1","6","Nowadays data is collected without any specific purpose, every activity of a machine or a human being is recorded, If needed in the future then the data will be analyzed. But here the question of trust arises as the data will go through many phases for the analysis by different parties. The data may contain some sensitive or private information that can be miss utilized by the organizations involved in the analysis stages. So it is needed for the hour to consider the data privacy issues very seriously. Data privacy refers to how to control the use of a piece of data by its relative importance. For example, someone will not hesitate to say his/her name to strangers but will not share mobile no. address until the stranger becomes familiar. In this digital age, the personal use of data privacy generally applied to critical personal information. From a business point of view, data privacy operates in a broader sense beyond the critical information of employees & customers. There is a general conclusion that AI & Machine Learning driven technologies are obstructed by data privacy issues as the ML uses large data sets to train & test. But can the obstacle block convert to a stepping stone? Yes, It can be. Imagine a scenario where no one is trust-able, so in that case, Blockchain enters the scene. Blockchain uses the data but in an anonymity way. So in this paper, we are proposing a way, how to combine Machine Learning & Blockchain to ensure data privacy.","","978-1-7281-6851-7","10.1109/ICCCNT49239.2020.9225342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225342","Machine Learning;Data Analysis;Blockchain;Integration;Data Privacy;Encryption","","cryptography;data privacy;distributed databases;learning (artificial intelligence)","blockchain;machine learning;data privacy","","","","25","","15 Oct 2020","","","IEEE","IEEE Conferences"
"Secret image protection using image fusion","C. Rejintal; M. Kumar","Department of ECE, MVJ College of Engineering, Bangalore, India; ML Department, MVJ College of Engineering, Bangalore, India","2016 IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","9 Jan 2017","2016","","","475","479","Images are considered for handling in different flelds. The paper has an algorithm to guard the key image whose privacy must be kept up and verify the dealer who needs to disseminate that key image to a numerous clients. For authentication purpose the key image and palm-print of dealer are fused. In this paper Dual Tree Discrete Wavelet Transform is applied on both key image and palm print, coefficients obtained from both images are being fused using Image Fusion technique. DTDWT is used to overcome the drawbacks of DWT. Image fusion is a strategy or a procedure of consolidating pertinent data from set of pictures into a solitary picture, the resultant picture got will be more finished and useful than the information pictures. The threshold secret sharing is used to distribute the fused image to many shares. This gives both privacy as well as verification about the dealer whoever sends the image. During decryption key image is known and the palm print of the dealer has to be reconstructed from the shares collected from authorized users, finally verification is done.","","978-1-5090-0774-5","10.1109/RTEICT.2016.7807866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807866","DTDWT;Image fusion;Threshold secret sharing;Reconstruction","Discrete wavelet transforms;Image fusion;Conferences;Encryption;Market research","data protection;discrete wavelet transforms;image fusion;image reconstruction;image segmentation;palmprint recognition;trees (mathematics)","secret image protection;image fusion;key image privacy;palmprint image;dual tree discrete wavelet transform;DTDWT;threshold secret sharing;decryption;image reconstruction","","","","7","","9 Jan 2017","","","IEEE","IEEE Conferences"
"VideoTrain: A Generative Adversarial Framework for Synthetic Video Traffic Generation","C. Kattadige; S. R. Muramudalige; K. N. Choi; G. Jourjon; H. Wang; A. Jayasumana; K. Thilakarathna","The University of Sydney,Sydney,Australia; Colorado State University,USA; The University of Sydney,Sydney,Australia; CSIRO Sydney,Data61,Australia; Colorado State University,USA; Colorado State University,USA; The University of Sydney,Sydney,Australia","2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)","5 Jul 2021","2021","","","209","218","Unlike the traditional Internet application such as web browsing and peer-to-peer(P2P), video streaming has been dominating the global network traffic for the past few years, raising many challenges for network providers. With the popularity of interactive videos, a.k.a 360° videos, resource requirement for video streaming has been further increased. Prior identification of these video traffic is useful for effective provisioning of network resources, yet it is difficult due to the end-to-end encryption of data. However, with the recent advances in Machine Learning (ML) methods, prior identification of these resource-demanding traffic types has become viable. Nonetheless, they require more training data, without which leads to poor performance. Collecting more training data may also pose issues related to delayed training time. To remedy this problem, in this paper, we propose a novel Generative Adversarial Network (GAN) based data generation solution to synthesise video streaming data targeting 360°/normal video classification. Taking over 600 actual video traces and generating ≈ 30000 new traces, our post-classification results show that we can achieve 5 - 15% of accuracy improvement compared to only having actual traces.","","978-1-6654-2263-5","10.1109/WoWMoM51794.2021.00034","Office of Justice Programs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469502","Encrypted video traffic;Data generation;ML classification","Wireless communication;Training;Training data;Telecommunication traffic;Machine learning;Streaming media;Generative adversarial networks","cryptography;image classification;interactive video;learning (artificial intelligence);neural nets;telecommunication traffic;video signal processing;video streaming","normal video classification;machine learning;Generative Adversarial Network based data generation solution;resource-demanding traffic types;end-to-end data encryption;interactive videos;global network traffic;video streaming;synthetic video traffic generation;Generative Adversarial framework","","","","39","","5 Jul 2021","","","IEEE","IEEE Conferences"
"Anomaly Based Intrusion Detection for IoT with Machine Learning","A. Shaver; Z. Liu; N. Thapa; K. Roy; B. Gokaraju; X. Yuan","North Carolina A&T State Univ,Computer Science Department,Greensboro,USA; North Carolina A&T State Univ,Computer Science Department,Greensboro,USA; North Carolina A&T State Univ,Computer Science Department,Greensboro,USA; North Carolina A&T State Univ,Computer Science Department,Greensboro,USA; North Carolina A&T State Univ,Computational Data Sci. and Eng. Department,Greensboro,USA; North Carolina A&T State Univ,Computer Science Department,Greensboro,USA","2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","10 May 2021","2020","","","1","6","The Internet of Things (IoT) is the network that connects smart devices over the Internet. These devices are increasingly found in every facet of life, providing distributed data computing power and improving the accessibility of everyday routines in many households. However, these connected devices expand and so does the risk that they become valuable targets for malicious threats. This is because, IoT devices have lower power and computation management, meaning that traditional methods of security like encryption or firewalls tend to be unworkable to secure these devices. Therefore, Intrusion Detection Systems (IDSs) provide an alternative for securing IoT devices, by classifying with anomaly detection, whether a network communication is a potential attack. Enhancing existing IDS by integrating various common machine learning models could provide a logical solution to this issue. In this study, we contribute by reviewing and comparing various machine learning (ML) models with intrusion detection. In this comparative analysis, the experimental results from the integrated ML models were promising with an achieved 99% accuracy rates in both binary and multiclass classifiers for intrusion detection.","2332-5615","978-1-7281-8243-8","10.1109/AIPR50011.2020.9425199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425199","IoT;IDS;Machine Learning","Training;Firewalls (computing);Intrusion detection;Pattern recognition;Encryption;Internet of Things;Security","computer network security;Internet;learning (artificial intelligence)","anomaly based Intrusion Detection;smart devices;distributed data computing power;everyday routines;connected devices;valuable targets;malicious threats;computation management;encryption;intrusion detection systems;securing IoT devices;anomaly detection;network communication;common machine learning models;integrated ML models","","","","30","","10 May 2021","","","IEEE","IEEE Conferences"
"Data Randomization and Cluster-Based Partitioning for Botnet Intrusion Detection","O. Y. Al-Jarrah; O. Alhussein; P. D. Yoo; S. Muhaidat; K. Taha; K. Kim","Electrical and Computer Engineering Department, Khalifa University of Science Technology and Research, Abu Dhabi, UAE; School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada; Department of Computing and Informatics, Bournemouth University, Poole, U.K.; Electrical and Computer Engineering Department, Khalifa University of Science Technology and Research, Abu Dhabi, UAE; Electrical and Computer Engineering Department, Khalifa University of Science Technology and Research, Abu Dhabi, UAE; School of Computing, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea","IEEE Transactions on Cybernetics","20 May 2017","2016","46","8","1796","1806","Botnets, which consist of remotely controlled compromised machines called bots, provide a distributed platform for several threats against cyber world entities and enterprises. Intrusion detection system (IDS) provides an efficient countermeasure against botnets. It continually monitors and analyzes network traffic for potential vulnerabilities and possible existence of active attacks. A payload-inspection-based IDS (PI-IDS) identifies active intrusion attempts by inspecting transmission control protocol and user datagram protocol packet's payload and comparing it with previously seen attacks signatures. However, the PI-IDS abilities to detect intrusions might be incapacitated by packet encryption. Traffic-based IDS (T-IDS) alleviates the shortcomings of PI-IDS, as it does not inspect packet payload; however, it analyzes packet header to identify intrusions. As the network's traffic grows rapidly, not only the detection-rate is critical, but also the efficiency and the scalability of IDS become more significant. In this paper, we propose a state-of-the-art T-IDS built on a novel randomized data partitioned learning model (RDPLM), relying on a compact network feature set and feature selection techniques, simplified subspacing and a multiple randomized meta-learning technique. The proposed model has achieved 99.984% accuracy and 21.38 s training time on a well-known benchmark botnet dataset. Experiment results demonstrate that the proposed methodology outperforms other well-known machine-learning models used in the same detection task, namely, sequential minimal optimization, deep neural network, C4.5, reduced error pruning tree, and randomTree.","2168-2275","","10.1109/TCYB.2015.2490802","Khalifa University of Science, Technology and Research-Korea Institute of Science and Technology (KAIST) Institute; KAIST, Korea; National Research Foundation of Korea through the Korea government (MSIP)(grant numbers:NRF-2015R1A2A2A01006812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312964","Botnet intrusion detection;efficient learning;ensembles;feature selection;machine-learning (ML)","Feature extraction;Computational modeling;Accuracy;Partitioning algorithms;Clustering algorithms;Intrusion detection;Data models","computer network security;digital signatures;learning (artificial intelligence);pattern clustering;telecommunication traffic;transport protocols","cluster-based partitioning;botnet intrusion detection;remotely-controlled compromised machines;distributed platform;intrusion detection system;network traffic;active attacks;payload-inspection-based IDS;active intrusion;transmission control protocol;user datagram protocol packet payload;attack signatures;PI-IDS;packet encryption;traffic-based IDS;T-IDS;packet header analysis;critical detection-rate;randomized data partitioned learning model;RDPLM;compact network feature set;feature selection techniques;subspacing technique;multiple randomized meta-learning technique;benchmark botnet dataset","","58","","53","","30 Oct 2015","","","IEEE","IEEE Journals"
"A Privacy Protected Fall Detection IoT System for Elderly Persons Using Depth Camera","X. Kong; Z. Meng; L. Meng; H. Tomiyama","Graduate School of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, Japan; Graduate School of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, Japan; College of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, Japan; College of Science and Engineering, Ritsumeikan University, 1-1-1 Noji-higashi, Kusatsu, Shiga, 525-8577, Japan","2018 International Conference on Advanced Mechatronic Systems (ICAMechS)","25 Oct 2018","2018","","","31","35","The proportion of the elderly persons in the world is constantly on the rise, and fall accidents have become a serious problem, especially for those who live alone. Currently, fall detection has attracted a lot of research attention and machine learning (ML) has shown promising performance in this task due to their strengths in person recognition. However, many existing methods using RGB images as the training data, resulting in the main information to be lost, or do not appropriately consider the effect of light, resulting in weak generalizability of the fall detection. Moreover, traditional methods pose a risk of leakage of personal privacy. This paper proposes a fall detection IoT system based on depth camera and fast Fourier transform (FFT) to overcome these problems. We first use depth camera to get the skeleton images of a person who is standing or falling down. We then get the characteristic quantity of these images and train them by ML to get the training model. Finally, we use FFT to encrypt images and detect the fall. We constructe a training database that includes 1131 images, and the experimental evaluation of the images demonstrates that our algorithm is effective for detecting falls and maintain privacy.","2325-0690","978-1-5386-7174-0","10.1109/ICAMechS.2018.8506987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8506987","fall detection;elderly persons;IoT system;privacy protection;machine learning","Skeleton;Senior citizens;Cameras;Privacy;Encryption;Training","accidents;assisted living;cameras;cryptography;data privacy;fast Fourier transforms;Internet of Things;learning (artificial intelligence);object detection","privacy protected fall detection IoT system;elderly persons;fall accidents;machine learning;person recognition;personal privacy;skeleton images;depth camera;fast Fourier transform;image encryption","","4","","16","","25 Oct 2018","","","IEEE","IEEE Conferences"
"A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security","M. A. Al-Garadi; A. Mohamed; A. K. Al-Ali; X. Du; I. Ali; M. Guizani","Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA; Department of Computer System and Technology, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of Computer Science and Engineering, Qatar University, Doha, Qatar","IEEE Communications Surveys & Tutorials","21 Aug 2020","2020","22","3","1646","1685","The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention. IoT is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020. However, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems have introduced new security challenges. Implementing security measures, such as encryption, authentication, access control, network and application security for IoT devices and their inherent vulnerabilities is ineffective. Therefore, existing security methods should be enhanced to effectively secure the IoT ecosystem. Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory novelty to practical machinery in several important applications. Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems. The goal of this work is to provide a comprehensive survey of ML methods and recent advances in DL methods that can be used to develop enhanced security methods for IoT systems. IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed. We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method. We discuss the opportunities and challenges involved in applying ML/DL to IoT security. These opportunities and challenges can serve as potential future research directions.","1553-877X","","10.1109/COMST.2020.2988293","NPRP from the Qatar National Research Fund (a member of Qatar Foundation)(grant numbers:8-408-2-172,12S-0305-190231); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072101","Deep learning;machine learning;Internet of Things security;security based intelligence;IoT big~data","Machine learning;Internet of Things;Tutorials;Electronic mail;Classification algorithms;Encryption","Internet of Things;learning (artificial intelligence);security of data;telecommunication security","deep learning methods;Things security;smart devices;fastest developing fields;estimated 50 billion devices;IoT systems;security challenges;implementing security measures;application security;IoT devices;existing security methods;IoT ecosystem;machine learning;machine intelligence;secure communication;security-based intelligence systems;ML methods;enhanced security methods;IoT security threats;inherent introduced threats;newly introduced threats;potential IoT system attack surfaces","","35","","291","IEEE","20 Apr 2020","","","IEEE","IEEE Journals"
"A High-Performance and Area-Efficient VLSI Architecture for the PRESENT Lightweight Cipher","J. G. Pandey; T. Goel; A. Karmakar","Central Electron. Eng. Res. Inst., Pilani, India; Acad. of Sci. & Innovative Res., Pilani, India; Central Electron. Eng. Res. Inst., Pilani, India","2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)","29 Mar 2018","2018","","","392","397","Security and privacy are of prime concern in the emerging internet of things (IoT) and cyber-physical systems (CPS) based applications. Lightweight cryptography plays an essential role in securing the data in this emerging pervasive computing environments. In this paper, we propose a high-performance and area-efficient VLSI architecture with 64-bit datapath for the PRESENT block cipher. The proposed architecture performs an integrated encryption/decryption operation for both 80-bit and 128-bit key lengths. The architecture is synthesized for the Virtex-5 XC5VLX110T FPGA device, available on the Xilinx ML-505 platform. It has been observed that the proposed architecture utilizes 0.73% and 0.87% of FPGA slices for 80-bit and 128-bit key lengths, respectively. A throughput of 410 Mbps and power consumption is about 16 mW for both the key lengths.","2380-6923","978-1-5386-3692-3","10.1109/VLSID.2018.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326959","Lightweight cryptography;PRESENT block cipher;Integrated encryption/decryption;VLSI architecture;FPGAs.","Ciphers;Computer architecture;Encryption;Clocks;Field programmable gate arrays;Registers","cryptography;field programmable gate arrays;Internet of Things;ubiquitous computing;VLSI","lightweight cipher;privacy;cyber-physical systems;lightweight cryptography;emerging pervasive computing environments;Virtex-5 XC5VLX110T FPGA device;datapath;area-efficient VLSI architecture;FPGA slices;encryption/decryption operation;Xilinx ML-505 platform;emerging internet of things;IoT;CPS","","4","","17","","29 Mar 2018","","","IEEE","IEEE Conferences"
"Secure SVM Training Over Vertically-Partitioned Datasets Using Consortium Blockchain for Vehicular Social Networks","M. Shen; J. Zhang; L. Zhu; K. Xu; X. Tang","School of Computer Science, Beijing Institute of Technology and State Key Laboratory of Cryptology, Beijing, China; School of Computer Science, Beijing Institute of Technology and State Key Laboratory of Cryptology, Beijing, China; School of Computer Science, Beijing Institute of Technology and State Key Laboratory of Cryptology, Beijing, China; Department of Computer Science, Tsinghua University and Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; School of Computer Science, Beijing Institute of Technology and State Key Laboratory of Cryptology, Beijing, China","IEEE Transactions on Vehicular Technology","18 Jun 2020","2020","69","6","5773","5783","Machine learning (ML) techniques are expected to be used for specific applications in Vehicular Social Networks (VSNs). Support vector machine (SVM) is one of the typical ML methods and widely used for its high efficiency. Due to the limitation of data sources, the data collected by different entities usually contain attributes that are quite different. However, in some real-world scenarios, when training an SVM classifier, many entities face the same problem that they are lacking in data with adequate attributes. Thus multiple entities are required to share data to combine a dataset with diverse attributes and then jointly train a comprehensive classifier. However, data privacy concerns are raised because of data sharing. To sovle the problem, we propose a privacy-preserving SVM classifier training scheme over vertically-partitioned datasets posessed by multiple data providers. In our scheme, we utilize consortium blockchain and threshold homomorphic cryptosystem to establish a secure SVM classifier training platform without a trusted third-party. We keep lots of training operations locally over original data and necessary interactions between participants are protected by the threshold Paillier and consortium blockchain. Security analysis proves that our scheme can preserve the privacy of the original data and the training intermediate values. Extensive experiments indicate that our scheme has high efficiency and no accuracy loss.","1939-9359","","10.1109/TVT.2019.2957425","National Basic Research Program of China (973 Program)(grant numbers:2018YFB0803405); National Natural Science Foundation of China(grant numbers:61972039,61872041,61602039); Natural Science Foundation of Beijing Municipality(grant numbers:4192050); China National Funds for Distinguished Young Scientists(grant numbers:61825204); Beijing Outstanding Young Scientist Program(grant numbers:BJJWZYJH01201910003011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919978","Privacy Preserving;Vehicular Social Networks;support vector machine;consortium blockchain","Support vector machines;Training;Encryption;Privacy","cryptography;data privacy;distributed databases;learning (artificial intelligence);pattern classification;social networking (online);support vector machines;telecommunication computing;telecommunication security;vehicular ad hoc networks","data sources;data privacy;data sharing;vertically-partitioned datasets;multiple data providers;consortium blockchain;threshold homomorphic cryptosystem;secure SVM classifier training platform;security analysis;secure SVM training;vehicular social networks;machine learning;support vector machine;privacy-preservation SVM classifier training","","15","","40","IEEE","3 Dec 2019","","","IEEE","IEEE Journals"
"Fast and Scalable Private Genotype Imputation Using Machine Learning and Partially Homomorphic Encryption","E. Sarkar; E. Chielle; G. Gürsoy; O. Mazonka; M. Gerstein; M. Maniatakos","Tandon School of Engineering, New York University, New York, NY, USA; New York University Abu Dhabi, Abu Dhabi, United Arab Emirates; Program in Computational Biology and Bioinformatics, Yale University, New Haven, CT, USA; New York University Abu Dhabi, Abu Dhabi, United Arab Emirates; Program in Computational Biology and Bioinformatics, Yale University, New Haven, CT, USA; Tandon School of Engineering, New York University, New York, NY, USA","IEEE Access","2 Jul 2021","2021","9","","93097","93110","The recent advances in genome sequencing technologies provide unprecedented opportunities to understand the relationship between human genetic variation and diseases. However, genotyping whole genomes from a large cohort of individuals is still cost prohibitive. Imputation methods to predict genotypes of missing genetic variants are widely used, especially for genome-wide association studies. Accurate genotype imputation requires complex statistical methods. Due to the data and computing-intensive nature of the problem, imputation is increasingly outsourced, raising serious privacy concerns. In this work, we investigate solutions for fast, scalable, and accurate privacy-preserving genotype imputation using Machine Learning (ML) and a standardized homomorphic encryption scheme, Paillier cryptosystem. ML-based privacy-preserving inference has been largely optimized for computation-heavy non-linear functions in a single-output multi-class classification setting. However, having a large number of multi-class outputs per genome per individual calls for further optimizations and/or approximations specific to this application. Here we explore the effectiveness of linear models for genotype imputation to convert them to privacy-preserving equivalents using standardized homomorphic encryption schemes. Our results show that performance of our privacy-preserving genotype imputation method is equivalent to the state-of-the-art plaintext solutions, achieving up to 99% micro area under curve score, even on real-world large-scale datasets up to 80,000 targets.","2169-3536","","10.1109/ACCESS.2021.3093005","New York University Abu Dhabi Global Ph.D. Fellowship Program; U.S. National Institutes of Health(grant numbers:K99 HG010909,R01 HG010749); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466098","Genotype imputation;machine learning;privacy-preserving computation","Bioinformatics;Genomics;Cryptography;Biological system modeling;Encryption;Computational modeling;Machine learning","","","","","","41","CCBY","28 Jun 2021","","","IEEE","IEEE Journals"
"Network traffic classification techniques and challenges","N. Al Khater; R. E. Overill","Department of Informatics, King's College London, United Kingdom; Department of Informatics, King's College London, United Kingdom","2015 Tenth International Conference on Digital Information Management (ICDIM)","14 Jan 2016","2015","","","43","48","The number of alleged crimes in computer networks had not increased until a few years ago. Real-time analysis has become essential to detect any suspicious activities. Network classification is the first step of network traffic analysis, and it is the core element of network intrusion detection systems (IDS). Although the techniques of classification have improved and their accuracy has been enhanced, the growing trend of encryption and the insistence of application developers to create new ways to avoid applications being filtered and detected are among the reasons that this field remains open for further research. This paper discusses how researchers apply Machine Learning (ML) algorithms in several classification techniques, utilising the statistical properties of the network traffic flow. It also outlines the next stage of our research, which involves investigating different classification techniques (supervised, semi-supervised, and unsupervised) that use ML algorithms to cope with real-world network traffic.","","978-1-4673-9152-8","10.1109/ICDIM.2015.7381869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381869","network traffic analysis;Machine Learning (ML);traffic classification;security","Feature extraction;Cryptography;Seismic measurements;Internet","computer network security;cryptography;learning (artificial intelligence);statistical analysis;telecommunication traffic","network traffic classification;computer networks;real-time analysis;network intrusion detection systems;IDS;accuracy enhancement;data encryption;machine learning algorithm;ML algorithm;statistical properties;network traffic flow;supervised classification technique;semisupervised classification technique;unsupervised classification technique","","14","","36","","14 Jan 2016","","","IEEE","IEEE Conferences"
"A Secure and Privacy-Preserving Machine Learning Model Sharing Scheme for Edge-Enabled IoT","X. Zhou; K. Xu; N. Wang; J. Jiao; N. Dong; M. Han; H. Xu","State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China; State Grid Beijing Electric Power Company, Beijing, China","IEEE Access","1 Feb 2021","2021","9","","17256","17265","With the popular use of IoT devices, edge computing has been widely applied in the Internet of things (IoT) and regarded as a promising solution for its wide distribution, decentralization, low latency. At the same time, in response to the massive computing data and intelligent requirements of various applications in the IoT, artificial intelligence (AI) technology has also achieved rapid development. As a result, edge intelligence (EI) for the Internet of Things has attracted widespread attention. Driven by the requirement that making full use of data, machine learning (ML) models trained in EI are usually shared. However, there may be some security and privacy issues due to the openness and heterogeneity of edge intelligence. How to ensure flexible data access and data security as well as the accountability for edge nodes and users in EI model sharing have become important issues. In this article, we propose a Ciphertext Policy Attribute Based Proxy Re-encryption (CP-ABPRE) scheme with accountability to address the security and privacy issues in EI model sharing. In our scheme, a user can delegate the access right to others to make model access more flexible. Furthermore, each entity that may need to be held accountable is embedded a unique ID to achieve traceability. Finally, security analysis and performance evaluation are given to prove that our scheme is CPA secure and does not lose much efficiency with more features.","2169-3536","","10.1109/ACCESS.2021.3051945","Science and Technology Project of State Grid Corporation of China(grant numbers:520223190047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326411","Internet of Things;edge intelligence;model sharing;CP-ABPRE;accountability","Data models;Servers;Computational modeling;Internet of Things;Cloud computing;Access control;Public key","computer network security;cryptography;data privacy;Internet of Things;learning (artificial intelligence)","model access;security analysis;CPA secure;privacy-preserving machine learning model;edge-enabled IoT;IoT devices;edge computing;massive computing data;edge intelligence;machine learning models;privacy issues;flexible data access;edge nodes;EI model sharing;ciphertext policy attribute based proxy re-encryption scheme","","","","39","CCBY","18 Jan 2021","","","IEEE","IEEE Journals"
"Intelligent and Adaptive Machine Learning-based Algorithm for Power Saving in Mobile Hotspot","K. K. Thangadorai; R. k. Saranappa; A. S. Ahmed; K. Murugesan; M. Singh Soni; R. Mundra; M. N. Sataraddi; S. Sriram; V. Singh; B. S. Kumar; M. M. Patil; D. Das","Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; Samsung R&D Institute India - Bangalore Pvt. Ltd,Bangalore,India; International Institute of Information Technology-Bangalore, Electronic City,Bangalore,India","2020 IEEE 17th Annual Consumer Communications & Networking Conference (CCNC)","26 Mar 2020","2020","","","1","6","In current Wi-Fi technology trend, Mobile Hotspot (MHS) or Soft Access Point (S-AP) is an integral part of our day-to-day life. At any time, MHS could be enabled as Wi-Fi Hotspot in mobility devices (smart phone, tablet) with cellular backhaul network (3G/4G/5G) and provides Internet access to client devices such as laptop, TV etc. Unlike Wi-Fi Access Point, which is typically a powered device, MHS is enabled as battery-operated device. In addition, MHS consumes higher power and reported as one of the primary Voice of Customer (VoC) issue. Due to high power consumption, many customers are skeptical about MHS feature and its continuous usage. Apart from few literatures, there is no specific IEEE 802.11 standard for MHS and its power management. In this paper, we have proposed a Machine Learning (ML) based Intelligent MHS Power Save (I-MHSPS) algorithm using Wi-Fi parameters such as RSSI, SNR, TX power and channel condition. In addition, we have used other contextual parameters such as client behavior, battery level, application usage and internet backhaul to improve the accuracy of our algorithm. In I-MHSPS, we have proposed Intelligent Transmit Power Control (I-TPC): MHS TX power regulation based on client vicinity, Intelligent Ultra Power Save (I-UPS): Applying different system power level for MHS operation and Intelligent Low Power Encryption (I-LPE): Enabling low power encryption for short range MHS. In our first experiment with I-TPC idea has reduced power consumption by 10-16% approximately when compared to existing methodologies. In second experiment for I-UPS, we have applied different system power levels for MHS operation and achieved power saving around 22% without any performance degradation. Further, in third experiment, using I-LPE method, we have observed the power required for encryption of data packets reduced by 20%.","2331-9860","978-1-7281-3893-0","10.1109/CCNC46108.2020.9045535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045535","Mobile Hotspot;Soft Access Point;Wi-Fi Power Management;Transmit Power Control;Low Power Encryption","","cellular radio;cryptography;energy conservation;Internet;learning (artificial intelligence);power control;telecommunication control;telecommunication power management;wireless LAN","Wi-Fi Hotspot;mobility devices;Internet access;client devices;Wi-Fi Access Point;powered device;battery-operated device;high power consumption;power management;Wi-Fi parameters;Intelligent Transmit Power Control;MHS TX power regulation;Intelligent Ultra Power Save;system power level;MHS operation;Intelligent Low Power Encryption;short range MHS;Mobile Hotspot;Wi-Fi technology;low power encryption;adaptive machine learning-based algorithm;soft access point;S-AP;cellular backhaul network;intelligent MHS power save algorithm;I-MHSPS algorithm;reduced power consumption;I-UPS;I-LPE method","","","","16","","26 Mar 2020","","","IEEE","IEEE Conferences"
"Hierarchical Key Management Scheme with Multilevel Secure Access","M. Ma; X. Yang; G. Shi; F. Li","Xidian University; Beijing Electronic Science and Technology Institute; Beijing Electronic Science and Technology Institute; Institute of Information Engineering, Chinese Academy of Sciences","2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)","2 Jan 2020","2019","","","97","102","With the rapid expansion of IoT, data collected by sensors and intelligent devices has a great value to Big Data analysis. However, privacy leakage is becoming one of most challenging concerns in information collection, sharing or analysis, and threatening the security of information economy such as data as a service. In this paper, we focused on the dynamic changes of the relationship of resource-constrained data suppliers and demanders, and proposed a hierarchical key management scheme with multilevel secure access (ML-HKM) based on Elliptic Curve Discrete Logarithm Problem. We present the system operations including setup, update, join and revoke to securely obtain the data encryption key and the multilevel mapping method to enhance the network extensible. At last, the scheme is analysed in correctness and security which indicates it is both forward secrecy and backward secrecy.","","978-1-7281-2542-8","10.1109/CyberC.2019.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945831","hierarchical key management, multilevel security, Elliptic Curve Discrete Logarithm Problem, IoT, forward and backward secrecy","Encryption;Elliptic curves;Level set;Public key;Internet of Things;Permission","computer network management;Internet of Things;public key cryptography","hierarchical key management scheme;multilevel secure access;data encryption key;multilevel mapping method;Big Data analysis;privacy leakage;elliptic curve discrete logarithm problem","","","","25","","2 Jan 2020","","","IEEE","IEEE Conferences"
"Properties of gsw and their applications","Y. Xiaoyuan; Z. Tanping; Z. Wei; T. Zhenlin","Key Laboratory of Network & Information Security under the Chinese People's Armed Police,Electronic Department, Engineering College of the Armed Police Force, Xi'an, 710086, China; Key Laboratory of Network & Information Security under the Chinese People's Armed Police,Electronic Department, Engineering College of the Armed Police Force, Xi'an, 710086, China; Key Laboratory of Network & Information Security under the Chinese People's Armed Police,Electronic Department, Engineering College of the Armed Police Force, Xi'an, 710086, China; Key Laboratory of Network & Information Security under the Chinese People's Armed Police,Electronic Department, Engineering College of the Armed Police Force, Xi'an, 710086, China","China Communications","25 Dec 2015","2015","12","11","1","8","In CRYPTO'13, Gentry et al. proposed a fully homomorphic encryption scheme, called GSW. We find that the scheme has three special properties, which are not sufficiently recognized and applied in current literatures. Property 1: Noise grows asymmetrically in multiplication. Property 2: Small noise in MultConst(C, α) . Property 3: Fixed noise bound when α is a power of 2 in MultConst(C, α) . We made use of property 1 to the Yi's private searching on streaming data protocol, called YBVX. Compared with YBVX, the four mainly aspects of efficiency in our protocol had been improved, the computation complexity of the sever decreased from O(ml<sup>2</sup> + μ)multi. + O(ml<sup>2</sup> + μ)add.+O(μd)enc. +O(μ)ADD. t o O(m +μ)multi. + O(m +μ)add.+ O(μd)enc.+O(μ) ADD; the space complexity decreased from O(ml<sup>2</sup> + μd) to O(m + μd) ; the communication complexity decreased from O(ml)+O(d|D|k) to O(m)+O(d|D|k) ; the computation complexity of the client decreased from O(ml)dec.+O(d | D |) enc to O(m)dec.+ O(d | D |)enc. what's more, the above three properties can have a variety of applications, ranging from improving the property of cryptographic prototypes to protocol building.","1673-5447","","10.1109/CC.2015.7366238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366238","","Protocols;Encryption;Complexity theory;Search problems;Dictionaries","cryptographic protocols","GSW;CRYPTO'13;homomorphic encryption scheme;streaming data protocol;computation complexity;space complexity;communication complexity;cryptographic prototypes;protocol building","","","","","","25 Dec 2015","","","IEEE","IEEE Magazines"
"GDPR Compliant Recruitment Platform using Smart Contracts and Executable Choreographies","V. Posea; C. Niţu; C. Damian; A. Panu; L. Alboaie","Junio,Iaşi,Romania; Junio,Iaşi,Romania; “Gheorghe Asachi” Technical University of Iasi,Faculty of Electrical Engineering,Iasi,Romania; Alexandru Ioan Cuza University of Iasi,Faculty of Computer Science,Iasi,Romania; Alexandru Ioan Cuza University of Iasi,Faculty of Computer Science,Iasi,Romania","2020 International Conference and Exposition on Electrical And Power Engineering (EPE)","18 Feb 2021","2020","","","103","108","This paper presents a recruiting application that is based on blockchain technology and uses PrivateSky platform, all ecosystem being developed in accordance with General Data Protection Regulation (GDPR). The presented application can be easily adapted to any industry recruitment methodology. It uses new privacy principles applied with help of blockchain technologies and the authors will present in the final paper some functionalities obtained with help of Machine Learning (ML) and Natural Language Processing (NLP) techniques.","2644-223X","978-1-7281-8126-4","10.1109/EPE50722.2020.9305669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305669","blockchain;GDPR;decentralized identities;PrivateSky","Companies;Blockchain;Recruitment;Public key;Encryption;Ecosystems;Regulation","blockchains;data privacy;data protection;learning (artificial intelligence);natural language processing;recruitment","GDPR compliant recruitment platform;smart contracts;executable choreographies;blockchain technology;PrivateSky platform;general data protection regulation;industry recruitment methodology;privacy principles;machine learning;natural language processing","","","","11","","18 Feb 2021","","","IEEE","IEEE Conferences"
"Towards the Deployment of Machine Learning Solutions in Network Traffic Classification: A Systematic Survey","F. Pacheco; E. Exposito; M. Gineste; C. Baudoin; J. Aguilar","Universite de Pau et des Pays de l’Adour, E2S UPPA, LIUPPA, Anglet, France; Universite de Pau et des Pays de l’Adour, E2S UPPA, LIUPPA, Anglet, France; D’epartement: Business Line Telecommunication, Research and Development Department, Thales Alenia Space, Toulouse, France; D’epartement: Business Line Telecommunication, Research and Development Department, Thales Alenia Space, Toulouse, France; Dpto. de Computacion, CEMISID, Facultad de Ingenieria, Universidad de Los Andes, Merida, Venezuela","IEEE Communications Surveys & Tutorials","31 May 2019","2019","21","2","1988","2014","Traffic analysis is a compound of strategies intended to find relationships, patterns, anomalies, and misconfigurations, among others things, in Internet traffic. In particular, traffic classification is a subgroup of strategies in this field that aims at identifying the application's name or type of Internet traffic. Nowadays, traffic classification has become a challenging task due to the rise of new technologies, such as traffic encryption and encapsulation, which decrease the performance of classical traffic classification strategies. Machine learning (ML) gains interest as a new direction in this field, showing signs of future success, such as knowledge extraction from encrypted traffic, and more accurate Quality of Service management. ML is fast becoming a key tool to build traffic classification solutions in real network traffic scenarios; in this sense, the purpose of this investigation is to explore the elements that allow this technique to work in the traffic classification field. Therefore, a systematic review is introduced based on the steps to achieve traffic classification by using ML techniques. The main aim is to understand and to identify the procedures followed by the existing works to achieve their goals. As a result, this survey paper finds a set of trends derived from the analysis performed on this domain; in this manner, the authors expect to outline future directions for ML-based traffic classification.","1553-877X","","10.1109/COMST.2018.2883147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543584","Internet traffic;traffic classification;machine learning;traffic monitoring","Feature extraction;Machine learning;Internet;Quality of service;Data mining;Tutorials;Systematics","Internet;learning (artificial intelligence);pattern classification;telecommunication traffic","encrypted traffic;traffic classification solutions;network traffic scenarios;traffic classification field;ML-based traffic classification;network traffic classification;traffic analysis;Internet traffic;traffic encryption;encapsulation;machine learning","","31","","210","","23 Nov 2018","","","IEEE","IEEE Journals"
"Machine Learning For Security: The Case of Side-Channel Attack Detection at Run-time","M. Mushtaq; A. Akram; M. K. Bhatti; M. Chaudhry; M. Yousaf; U. Farooq; V. Lapotre; G. Gogniat","Lab-STICC, University of South Brittany (UBS), Lorient, France; University of California, Davis, USA; ECLab, Information Technology University, Lahore, Pakistan; ECLab, Information Technology University, Lahore, Pakistan; ECLab, Information Technology University, Lahore, Pakistan; Department of E&C Engineering, Dhofar University, Salalah, Oman; Lab-STICC, University of South Brittany (UBS), Lorient, France; Lab-STICC, University of South Brittany (UBS), Lorient, France","2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS)","20 Jan 2019","2018","","","485","488","This paper presents experimental evaluation and comparative analysis on the use of various Machine Learning (ML) models for detecting Cache-based Side Channel Attacks (CSCAs) in Intel's x86 architecture. The paper provides performance evaluation of ML models based on run-time detection accuracy, speed, computational overhead, and distribution of error in terms of false positives and false negatives. Experiments are performed using state-of-the-art CSCAs namely; Flush+Reload and Flush+Flush attacks, under realistic load conditions on RSA and AES crypto-systems. The paper provides quantitative & qualitative analysis of at least 12 ML models being used for CSCA detection for the first time.","","978-1-5386-9562-3","10.1109/ICECS.2018.8617994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8617994","Cache-based Side-Channel Attacks;Cryptography;RSA;AES;Flush+Reload;Flush+Flush;Detection;Machine Learning","Machine learning;Load modeling;Hardware;Analytical models;Side-channel attacks;Encryption","cache storage;cryptography;data flow analysis;instruction sets;learning (artificial intelligence);software performance evaluation","CSCA detection;performance evaluation;side-channel attack detection;run-time detection;Intel x86 architecture;cache-based side channel attacks;machine learning models;ML models","","5","","29","","20 Jan 2019","","","IEEE","IEEE Conferences"
"Preventing Neural Network Model Exfiltration in Machine Learning Hardware Accelerators","M. Isakov; L. Bu; H. Cheng; M. A. Kinsy","Adaptive and Secure Computing Systems Laboratory, Boston University; Adaptive and Secure Computing Systems Laboratory, Boston University; Adaptive and Secure Computing Systems Laboratory, Boston University; Adaptive and Secure Computing Systems Laboratory, Boston University","2018 Asian Hardware Oriented Security and Trust Symposium (AsianHOST)","10 Jan 2019","2018","","","62","67","Machine learning (ML) models are often trained using private datasets that are very expensive to collect, or highly sensitive, using large amounts of computing power. The models are commonly exposed either through online APIs, or used in hardware devices deployed in the field or given to the end users. This provides an incentive for adversaries to steal these ML models as a proxy for gathering datasets. While API-based model exfiltration has been studied before, the theft and protection of machine learning models on hardware devices have not been explored as of now. In this work, we examine this important aspect of the design and deployment of ML models. We illustrate how an attacker may acquire either the model or the model architecture through memory probing, side-channels, or crafted input attacks, and propose (1) power-efficient obfuscation as an alternative to encryption, and (2) timing side-channel countermeasures.","","978-1-5386-7471-0","10.1109/AsianHOST.2018.8607161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607161","Neural network;model exfiltration;hardware security;model theft;memory probing;side-channels;inference","Hardware;Computational modeling;Training;Machine learning;Data models;Neural networks;Context modeling","cryptography;learning (artificial intelligence);neural nets;security of data","machine learning hardware accelerators;machine learning models;private datasets;computing power;hardware devices;ML models;API-based model exfiltration;online API;neural network model exfiltration;crafted input attacks;timing side-channel countermeasures","","5","","20","","10 Jan 2019","","","IEEE","IEEE Conferences"
"Analyzing and evaluating security features in software requirements","R. Malhotra; A. Chug; A. Hayrapetian; R. Raje","Department of Software Engineering, Delhi Technological University, Shahbad, Bawana, Delhi - 110042, India; University School of Information and Communication Technology (USICT), GGSIP University, Sector-16C, DWARKA, New Delhi-110077, India; Department of Computer and Information Science, Indiana University-Purdue University, 723 W. Michigan, Street, SL 280H, Indianapolis, IN 46202-5132; Department of Computer and Information Science, Indiana University-Purdue University, 723 W. Michigan, Street, SL 280H, Indianapolis, IN 46202-5132","2016 International Conference on Innovation and Challenges in Cyber Security (ICICCS-INBUSH)","15 Aug 2016","2016","","","26","30","Software requirements, for complex projects, often contain specifications of non-functional attributes (e.g., security-related features). The process of analyzing such requirements is laborious and error prone. Due to the inherent free-flowing nature of software requirements, it is tempting to apply Natural Language Processing (NLP) based Machine Learning (ML) techniques for analyzing these documents from the point of view of comprehensiveness and consistency. In this paper, we propose novel semi-automatic methodology that can assess the security requirements of the software system from the perspective of completeness, contradiction, and inconsistency. Security standards introduced by the ISO are used to construct a model for classifying security-based requirements using NLP-based ML techniques. Hence, this approach aims to identify the appropriate structures that underlie software requirement documents. Once such structures are formalized and empirically validated, they will provide guidelines to software organizations for generating comprehensive and unambiguous requirement specification documents as related to security-oriented features. The proposed solution will assist organizations during the early phases of developing secure software and reduce overall development effort and costs.","","978-1-5090-2084-3","10.1109/ICICCS.2016.7542334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542334","Software Requirements;Security;Quality of Service;Natural Language Processing;Concept Graphs;Machine Learning","Software;Standards;Authentication;Natural language processing;Encryption;Technological innovation","ISO standards;learning (artificial intelligence);natural language processing;pattern classification;security of data;software engineering","security feature evaluation;natural language processing;machine learning techniques;semi-automatic methodology;software system security requirements;security standards;ISO;NLP-based ML techniques;software requirement documents;software organizations;security-oriented features;secure software development","","2","","11","","15 Aug 2016","","","IEEE","IEEE Conferences"
"A Many-Objective Optimization Based Intelligent Intrusion Detection Algorithm for Enhancing Security of Vehicular Networks in 6G","Z. Zhang; Y. Cao; Z. Cui; W. Zhang; J. Chen","School of Computer Science and Technology, the School of Electronic Information Engineering and the Shanxi Key Laboratory of Advanced Control and Equipment intelligence, Taiyuan University of Science and Technology, Taiyuan, Shanxi, China; School of Information, Beijing Wuzi University, Beijing, China; School of Computer Science and Technology, Taiyuan University of Science and Technology, Taiyuan, Shanxi, China; State Key Laboratory of Intelligent Control and Management of Complex Systems, Institute of Automation Chinese Academy of Sciences, Beijing, China; Swinburne University of Technology, Melbourne, Australia","IEEE Transactions on Vehicular Technology","8 Jul 2021","2021","70","6","5234","5243","With accelerated ensemble of the Internet of Things technology and automotive industry, vehicular network has been established as powerful tools. However, it is a significant challenge for dynamic and heterogeneous vehicular network to meet high requirements of the sixth-generation (6G) network such as high reliability and high security. To address this challenge, we design a novel weight-based ensemble machine learning algorithm (WBELA) to identify abnormal messages of vehicular Controller Area Network (CAN) bus network. Then, we establish a model based on many-objective optimization for intrusion detection of CAN bus network. To support this model, a many-objective optimization algorithm based on balance convergence and diversity (MaOEA-BCD) is designed. Open-source CAN bus message data sets and tamper attack scenarios are used to evaluate the effectiveness of proposed algorithm for different ID data frames. Experimental results revealed that proposed methods significantly enhance precision, reduce the false positive rate and have better performance than other methods so as to enhance security of vehicular networks in 6G.","1939-9359","","10.1109/TVT.2021.3057074","National Key R&D Program of China(grant numbers:2018YFC1604000); National Natural Science Foundation of China(grant numbers:61 806 138,61 772 478,U1636220,61961160707,61 976 212); Key R&D program of Shanxi Province(grant numbers:201903D121119); Key R&D program of Shanxi Province(grant numbers:201903D421048); Postgraduate Education Innovation Project of Shanxi Province(grant numbers:2020SY437); Natural Science Foundation of Shanxi Province(grant numbers:201801D121127); Australian Research Council(grant numbers:DP190101893,DP170100136,LP180100758); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347691","Controller area network (CAN);intrusion detection;machine learning (ML);many-objective optimization;vehicular networks security","Intrusion detection;Security;6G mobile communication;Data models;Protocols;Optimization;Encryption","","","","","","36","IEEE","4 Feb 2021","","","IEEE","IEEE Journals"
"A Digital DNA Sequencing Engine for Ransomware Detection Using Machine Learning","F. Khan; C. Ncube; L. K. Ramasamy; S. Kadry; Y. Nam","Higher Colleges of Technology, Dubai, United Arab Emirates; Department of Computer and Information Sciences, British University in Dubai, Dubai, United Arab Emirates; Hindusthan College of Engineering and Technology, Coimbatore, India; Department of Mathematics and Computer Science, Faculty of Science, Beirut Arab University, Beirut, Lebanon; Department of Computer Science and Engineering, Soonchunhyang University, Asan, South Korea","IEEE Access","7 Jul 2020","2020","8","","119710","119719","Malware is `malicious software' programs that carry out many of the cyberattacks on the Internet, including cybercrime, fraud, scams and nation-state cyberwar. These malicious software programs come in a wide range of different classifications such as viruses, Trojans, worms, spyware, botnet malware, ransomware, Rootkit, etc. Ransomware is class of malware that holds the victim's data hostage by encrypting the data on a user's computer to make it unavailable to the user and only decrypt it after the user pays a ransom in the form of a sum of money. To avoid detection, different variants of ransomware utilise one or more techniques in their attack flow including Machine Learning (ML) algorithms. There is, therefore, a need to understand the techniques used ransomware development and their deployment strategy in order to understand their attack flow better to develop appropriate countermeasures. In this paper, we propose DNAact-Ran, A Digital DNA Sequencing Engine for Ransomware Detection Using Machine Learning. DNAact-Ran utilises Digital DNA sequencing design constraints and k-mer frequency vector. To measure the efficacy of the proposed approach, we evaluated DNAact-Run on 582 ransomware and 942 goodware instances to measure the performance of precision, recall, f-measure and accuracy. Compared to other methods, the evaluation results show that DNAact-Run can predict and detect ransomware accurately and effectively.","2169-3536","","10.1109/ACCESS.2020.3003785","Korea Institute for Advancement of Technology (KIAT) through the Korea Government (Competency Development Program for Industry Specialist)(grant numbers:MOTIE P0012724); Soonchunhyang University Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121260","Ransomware;digital DNA sequence;machine learning;active learning","Ransomware;DNA;Cryptography;Sequential analysis;Engines;Machine learning algorithms","biocomputing;computer network security;cryptography;Internet;invasive software;learning (artificial intelligence)","k-mer frequency vector;ML algorithm;attack flow;data encryption;data hostage;Internet;cyberattacks;digital DNA sequencing engine;digital DNA sequencing design constraints;classifications;nation-state cyberwar;malicious software programs;DNAact-Run;ransomware detection;ransomware development;machine learning algorithms","","1","","29","CCBY","19 Jun 2020","","","IEEE","IEEE Journals"
"ML-augmented Methodology for Fast Thermal Side-channel Emission Analysis","N. Chang; D. Zhu; L. Lin; D. Selvakumaran; J. Wen; S. Pan; W. Xia; H. Chen; C. Chow; G. Chen","ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; ANSYS, Inc.,San Jose,USA; National Taiwan University,Taiwan","2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)","11 Mar 2021","2021","","","463","468","Accurate side-channel attacks can non-invasively or semi-invasively extract secure information from hardware devices using ""side- channel"" measurements. The thermal profile of an IC is one class of side channel that can be used to exploit the security weaknesses in a design. Measurement of junction temperature from an on-chip thermal sensor or top metal layer temperature using an infrared thermal image of an IC with the package being removed can disclose secret keys of a cryptographic design through correlation power analysis. In order to identify the design vulnerabilities to thermal side channel attacks, design time simulation tools are highly important. However, simulation of thermal side-channel emission is highly complex and computationally intensive due to the scale of simulation vectors required and the multi-physics simulation models involved. Hence, in this paper, we have proposed a fast and comprehensive Machine Learning (ML) augmented thermal simulation methodology for thermal Side-Channel emission Analysis (SCeA). We have developed an innovative tile-based Delta-T Predictor using a data-driven DNN-based thermal solver. The developed tile based Delta-T Predictor temperature is used to perform the thermal side-channel analysis which models the scenario of thermal attacks with the measurement of junction temperature. This method can be 100-1000x faster depending on the size of the chip compared to traditional FEM-based thermal solvers with the same level of accuracy. Furthermore, this simulation allows for the determination of location- dependent wire temperature on the top metal layer to validate the scenario of thermal attack with top metal layer temperature. We have demonstrated the leakage of the encryption key in an 128-bit AES chip using both proposed tile-based temperature calculations and top metal wire temperature calculations, quantified by simulation MTD (Measurements-to-Disclosure).","2153-697X","978-1-4503-7999-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371609","","Temperature measurement;Temperature dependence;Computational modeling;Wires;Metals;Side-channel attacks;Thermal analysis","","","","","","14","","11 Mar 2021","","","IEEE","IEEE Conferences"
"Verifying and Synthesizing Constant-Resource Implementations with Types","V. C. Ngo; M. Dehesa-Azuara; M. Fredrikson; J. Hoffmann","Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA","2017 IEEE Symposium on Security and Privacy (SP)","26 Jun 2017","2017","","","710","728","Side channel attacks have been used to extract critical data such as encryption keys and confidential user data in a variety of adversarial settings. In practice, this threat is addressed by adhering to a constant-time programming discipline, which imposes strict constraints on the way in which programs are written. This introduces an additional hurdle for programmers faced with the already difficult task of writing secure code, highlighting the need for solutions that give the same source-level guarantees while supporting more natural programming models. We propose a novel type system for verifying that programs correctly implement constant-resource behavior. Our type system extends recent work on automatic amortized resource analysis (AARA), a set of techniques that automatically derive provable upper bounds on the resource consumption of programs. We devise new techniques that build on the potential method to achieve compositionality, precision, and automation. A strict global requirement that a program always maintains constant resource usage is too restrictive for most practical applications. It is sufficient to require that the program's resource behavior remain constant with respect to an attacker who is only allowed to observe part of the program's state and behavior. To account for this, our type system incorporates information flow tracking into its resource analysis. This allows our system to certify programs that need to violate the constant-time requirement in certain cases, as long as doing so does not leak confidential information to attackers. We formalize this guarantee by defining a new notion of resource-aware noninterference, and prove that our system enforces it. Finally, we show how our type inference algorithm can be used to synthesize a constant-time implementation from one that cannot be verified as secure, effectively repairing insecure programs automatically. We also show how a second novel AARA system that computes lower bounds on resource usage can be used to derive quantitative bounds on the amount of information that a program leaks through its resource use. We implemented each of these systems in Resource Aware ML, and show that it can be applied to verify constant-time behavior in a number of applications including encryption and decryption routines, database queries, and other resource-aware functionality.","2375-1207","978-1-5090-5533-3","10.1109/SP.2017.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7958606","Language-based security;timing channels;information flow;resource analysis;static analysis","Semantics;Standards;Cognition;Syntactics;Encryption;Programming","cryptography;inference mechanisms;program verification;resource allocation","constant-resource behavior implementations;side channel attacks;programs verification;automatic amortized resource analysis;AARA;resource consumption;information flow tracking;resource-aware noninterference;type inference algorithm;resource aware ML","","3","","95","","26 Jun 2017","","","IEEE","IEEE Conferences"
"RF-PUF: Enhancing IoT Security Through Authentication of Wireless Nodes Using <italic>In-Situ</italic> Machine Learning","B. Chatterjee; D. Das; S. Maity; S. Sen","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Internet of Things Journal","24 Feb 2019","2019","6","1","388","398","Traditional authentication in radio-frequency (RF) systems enable secure data communication within a network through techniques such as digital signatures and hash-based message authentication codes (HMAC), which suffer from key-recovery attacks. State-of-the-art Internet of Things networks such as Nest also use open authentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery forgery (CSRF), which shows that these techniques may not prevent an adversary from copying or modeling the secret IDs or encryption keys using invasive, side channel, learning or software attacks. Physical unclonable functions (PUFs), on the other hand, can exploit manufacturing process variations to uniquely identify silicon chips which makes a PUF-based system extremely robust and secure at low cost, as it is practically impossible to replicate the same silicon characteristics across dies. Taking inspiration from human communication, which utilizes inherent variations in the voice signatures to identify a certain speaker, we present RF-PUF: a deep neural network-based framework that allows real-time authentication of wireless nodes, using the effects of inherent process variation on RF properties of the wireless transmitters (Tx), detected through in-situ machine learning at the receiver (Rx) end. The proposed method utilizes the already-existing asymmetric RF communication framework and does not require any additional circuitry for PUF generation or feature extraction. The burden of device identification is completely shifted to the gateway Rx, similar to the operation of a human listener's brain. Simulation results involving the process variations in a standard 65-nm technology node, and features such as local oscillator offset and I-Q imbalance detected with a neural network having 50 neurons in the hidden layer indicate that the framework can distinguish up to 4800 Tx(s) with an accuracy of 99.9% [≈99% for 10000 Tx(s)] under varying channel conditions, and without the need for traditional preambles. The proposed scheme can be used as a stand-alone security feature, or as a part of traditional multifactor authentication.","2327-4662","","10.1109/JIOT.2018.2849324","National Science Foundation(grant numbers:1719235); Semiconductor Research Corporation(grant numbers:2720.001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390918","Artificial neural networks (ANNs);authentication;deep neural network;device signatures;Internet-of-Things (IoT);machine learning (ML);physical unclonable function (PUF);radio frequency (RF);security","Receivers;Radio frequency;Authentication;Radio transmitters;Machine learning;Object recognition","authorisation;cryptographic protocols;cryptography;digital signatures;Internet of Things;learning (artificial intelligence);neural nets;radio receivers","RF-PUF;deep neural network-based framework;real-time authentication;wireless nodes;inherent process variation;RF properties;wireless transmitters;in-situ machine;receiver end;asymmetric RF communication framework;feature extraction;human listener;stand-alone security feature;traditional multifactor authentication;radio-frequency systems;secure data communication;digital signatures;message authentication codes;open authentication;OAuth 2;cross-site-recovery forgery;encryption keys;software attacks;physical unclonable functions;PUFs;silicon chips;PUF-based system;silicon characteristics;human communication;voice signatures;IoT security;key-recovery attacks;Internet of Things networks","","44","","47","","20 Jun 2018","","","IEEE","IEEE Journals"
"MTRAC - discovering M2M devices in cellular networks from coarse-grained measurements","A. Bär; P. Svoboda; P. Casas","FTW, Vienna, Austria; TU Vienna, Austria; FTW, Vienna, Austria","2015 IEEE International Conference on Communications (ICC)","10 Sep 2015","2015","","","667","672","Machine-to-Machine (M2M) network traffic is becoming highly relevant in nowadays cellular networks. The ever-increasing number of M2M devices is heavily modifying the traffic patterns observed in cellular networks, and the interest in discovering and tracking these devices is rapidly growing among operators. In this paper we introduce MTRAC, a complete approach for M2M TRAffic Classification, capable of discovering M2M devices from coarse-grained measurements. MTRAC uses different Machine Learning (ML) algorithms to unveil M2M devices in cellular networks. It relies on very simple traffic descriptors to characterize the communication patterns of each device. These descriptors are robust to traffic encryption techniques, and improve the portability of the MTRAC approach to other network scenarios. MTRAC is implemented on top of DBStream, a novel Data Stream Warehouse which allows to classify M2M devices in an on-line basis, using different temporal and logical traffic aggregations. We study the performance of MTRAC in the on-line classification of more than two months of traffic observed in a operational, nationwide cellular network, comparing different ML algorithms and different traffic aggregation techniques. To the best of our knowledge, MTRAC is the first ML-based approach for automatic M2M device classification in operational cellular networks.","1938-1883","978-1-4673-6432-4","10.1109/ICC.2015.7248398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248398","Machine-to-Machine Traffic;DBStream;On-line Traffic Classification;Machine Learning;Cellular Networks","World Wide Web;Classification algorithms;Performance evaluation","cellular radio;cryptography;learning (artificial intelligence);telecommunication computing;telecommunication traffic","machine-to-machine network traffic;cellular networks;M2M traffic classification;MTRAC;coarse-grained measurements;machine learning;traffic encryption;data stream warehouse;DBStream;temporal traffic aggregations;logical traffic aggregations;automatic M2M device classification","","3","","14","","10 Sep 2015","","","IEEE","IEEE Conferences"
"A Cloud-based Mobile Healthcare Monitoring Framework with Location Privacy Preservation","M. A. Abdo; A. A. Abdel-Hamid; H. A. Elzouka","Arab Academy for Science, Technology and Maritime Transport,College of Engineering and Technology,Computer Engineering Department,Egypt; Arab Academy for Science, Technology and Maritime Transport,College of Computing and Information Technology,Computer Science Department,Egypt; Arab Academy for Science, Technology and Maritime Transport,College of Engineering and Technology,Computer Engineering Department,Egypt","2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT)","8 Jan 2021","2020","","","1","8","Nowadays, ubiquitous healthcare monitoring applications are becoming a necessity. In a pervasive smart healthcare system, the user's location information is always transmitted periodically to healthcare providers to increase the quality of the service provided to the user. However, revealing the user's location will affect the user's privacy. This paper presents a novel cloud-based secure location privacy-preserving mobile healthcare framework with decision-making capabilities. A user's vital signs are sensed possibly through a wearable healthcare device and transmitted to a cloud server for securely storing user's data, processing, and decision making. The proposed framework integrates a number of features such as machine learning (ML) for classifying a user's health state, and crowdsensing for collecting information about a person's privacy preferences for possible locations and applying such information to a user who did not set his privacy preferences. In addition to location privacy preservation methods (LPPM) such as obfuscation, perturbation and encryption to protect the location of the user and provide a secure monitoring framework. The proposed framework detects clear emergency cases and quickly decides about sending a help message to a healthcare provider before sending data to the cloud server. To validate the efficiency of the proposed framework, a prototype is developed and tested. The obtained results from the proposed prototype prove its feasibility and utility. Compared to the state of art, the proposed framework offers an adaptive context-based decision for location sharing privacy and controlling the trade-off between location privacy and service utility.","","978-1-7281-9673-2","10.1109/3ICT51146.2020.9311999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311999","location privacy;crowdsensing;obfuscation;cloud computing;personal health monitoring system;context-awareness","Data privacy;Technological innovation;Informatics;Art;Sensitivity;Monitoring;Wearable computers","cloud computing;data privacy;decision making;health care;mobile computing;patient monitoring;ubiquitous computing","privacy preferences;possible locations;person;securely storing user;wearable healthcare device;decision-making capabilities;novel cloud-based secure location privacy-preserving mobile healthcare framework;location information;pervasive smart healthcare system;ubiquitous healthcare monitoring applications;cloud-based mobile healthcare monitoring framework;location sharing privacy;adaptive context-based decision;cloud server;healthcare provider;secure monitoring framework;location privacy preservation methods","","","","29","","8 Jan 2021","","","IEEE","IEEE Conferences"
"Fast, Reliable, and Secure Drone Communication: A Comprehensive Survey","V. Hassija; V. Chamola; A. Agrawal; A. Goyal; N. C. Luong; D. Niyato; F. R. Yu; M. Guizani","Department of Computer Science and IT, Jaypee Institute of Information Technology, Noida, India 201304.; Department of Electrical and Electronics Engineering & APPCAIR, BITS-Pilani, Pilani Campus, India 333031.; Department of Computer Science and IT, Jaypee Institute of Information Technology, Noida, India 201304.; Department of Computer Science and IT, Jaypee Institute of Information Technology, Noida, India 201304.; Faculty of Computer Science, PHENIKAA University and is with PHENIKAA Research and Technology Institute (PRATI), Hanoi, Vietnam.; School of Computer Science and Engineering, Nanyang Technological University, Singapore.; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON K1S 5B6, Canada.; Computer Science and Engineering Department, Qatar University, Qatar. (e-mail: mguizani@ieee.org)","IEEE Communications Surveys & Tutorials","","2021","PP","99","1","1","Drone security is currently a major topic of discussion among researchers and industrialists. Although there are multiple applications of drones, if the security challenges are not anticipated and required architectural changes are not made, the upcoming drone applications will not be able to serve their actual purpose. Therefore, in this paper, we present a detailed review of the security-critical drone applications, and security-related challenges in drone communication such as DoS attacks, Man-in-the-middle attacks, De-Authentication attacks, and so on. Furthermore, as part of solution architectures, the use of Blockchain, Software Defined Networks (SDN), Machine Learning, and Fog/Edge computing are discussed as these are the most emerging technologies. Drones are highly resource-constrained devices and therefore it is not possible to deploy heavy security algorithms on board. Blockchain can be used to cryptographically store all the data that is sent to/from the drones, thereby saving it from tampering and eavesdropping. Various ML algorithms can be used to detect malicious drones in the network and to detect safe routes. Additionally, the SDN technology can be used to make the drone network reliable by allowing the controller to keep a close check on data traffic, and fog computing can be used to keep the computation capabilities closer to the drones without overloading them.","1553-877X","","10.1109/COMST.2021.3097916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9488323","Blockchain;Drone applications;Drone Security;Fog Computing;Machine Learning;Software Defined Networks;UAV.","Drones;Security;Privacy;Ad hoc networks;Tutorials;Encryption;Computer science","","","","","","","IEEE","16 Jul 2021","","","IEEE","IEEE Early Access Articles"
"Decomposing the Inverse of a Masked Vector in an Isomorphic Galois Field for Perfectly Masked S-Box","Y. Kodera; Y. Taketa; T. Kusaka; Y. Nogami",Okayama University; Okayama University; Okayama University; Okayama University,"2019 Seventh International Symposium on Computing and Networking (CANDAR)","16 Jan 2020","2019","","","157","163","The increment of opportunities for using machine learning (ML) technologies has brought a new threat to cryptosystems. As a remarkable example, the ML technologies have gradually been employed in the side-channel attack (SCA) to obtain sensitive information. In this paper, the authors focus on the structure of a masked S-Box in AES, which aims to equip the SCA resistance even for the attacks using the ML technologies. More precisely, this paper analyzes the mathematical structure of the inverse operation over F_(2^4)^2 which is an isomorphic field for obtaining efficient arithmetic for the AES, so that all functions in the encryption scheme can handle masked data as it is. The mathematical structure is realized by introducing several mathematical tools such as the Gauss periods and the Itoh-Tsujii inversion algorithm, and as a result, we clarified the factors of the coefficients of A^-1 for an element A ϵ F_(2^4)^2. It enables us to generate the corresponding element directly, which allows canceling the mask even after processing the SubBytes.","2379-1896","978-1-7281-4725-3","10.1109/CANDAR.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8958480","AES, masked S Box, isomorphic field F_(2^4)^2, Gauss periods, Itoh Tsujii inversion algorithm","","cryptography;Galois fields;vectors","masked vector;isomorphic galois field;perfectly masked S-Box;machine learning technologies;ML technologies;side-channel attack;sensitive information;AES;Itoh-Tsujii inversion algorithm;SCA","","","","21","","16 Jan 2020","","","IEEE","IEEE Conferences"
"How to choose from different botnet detection systems?","F. Haddadi; D. Phan; A. N. Zincir-Heywood","Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada","NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium","4 Jul 2016","2016","","","1079","1084","Given that botnets represent one of the most aggressive threats against cybersecurity, various detection approaches have been studied. However, whichever approach is used, the evolving nature of botnets and the required pre-defined botnet detection rule sets employed may affect the performance of detection systems. In this work, we explore the effectiveness two rule based systems and two machine learning (ML) based techniques with different feature extraction methods (packet payload based and traffic flow based). The performance of these detection systems range from 0% to 100% on thirteen public botnet data sets (i.e. CTU-13). We further analyze the performances of these systems in order to understand which type of a detection system is more effective for which type of an application.","2374-9709","978-1-5090-0223-8","10.1109/NOMS.2016.7502964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502964","Botnet detection;feature extraction;traffic analysis","Feature extraction;Payloads;Malware;Conferences;IP networks;Ports (Computers);Encryption","invasive software","botnet detection systems;cybersecurity;two rule based systems;two machine learning based techniques;feature extraction methods;packet payload based;traffic flow based","","4","","19","","4 Jul 2016","","","IEEE","IEEE Conferences"
"A Survey on Attack Detection Methods For IOT Using Machine Learning And Deep Learning","M. R. Babu; K. N. Veena","Reva University,School of Electronics and communication Engineering,Bangalore,India; Reva University,School of Electronics and communication Engineering,Bangalore,India","2021 3rd International Conference on Signal Processing and Communication (ICPSC)","15 Jun 2021","2021","","","625","630","The Internet of Things (IoT) models are getting more complicated day by day with the rising demand in IoT automated network system. As the devices use wireless medium for broadcasting the data, it is easy to target for an attack. Due to the addition of different protocols in IoT, lakhs of attacks are emerging every day, which often provokes the computing process worsen, unstable, non-effective as well. In the local network, the normal communication attack is restricted to small local domain or local nodes. However, the attack present in IoT devices gets expanded to a large area that would cause destructive effects. The heterogeneity, distribution of IoT services/applications make the security of IoT a more challenging and complex one. Implementing security measures, such as encryption, authentication, access control, network security and application security, for IoT devices and their inherent vulnerabilities is ineffective. Thus, existing security techniques should be improved to secure the IoT environment viably. (ML/DL) have progressed impressively throughout the most recent couple of years, and machine intelligence has transitioned from laboratory curiosity to practical machinery in various significant applications. The objective of this work is to give a thorough study of ML techniques and ongoing advances in DL methods that can be utilized to create upgraded attack detection models for IoT frameworks. We discuss the features and research gaps for each method in applying Machine learning and deep learning to IoT security.","","978-1-6654-2864-4","10.1109/ICSPC51351.2021.9451740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451740","IoT;Security;Attack detection;t;Machine learning;Deep learning","Deep learning;Wireless communication;Signal processing algorithms;Whales;Process control;Feature extraction;Classification algorithms","authorisation;computer network security;deep learning (artificial intelligence);Internet of Things","network security;application security;IoT devices;security techniques;IoT environment;upgraded attack detection models;IoT frameworks;Machine learning;deep learning;IoT security;attack detection methods;IoT automated network system;local network;normal communication attack;local domain;local nodes;security measures;Internet of Things models;access control;authentication","","","","27","","15 Jun 2021","","","IEEE","IEEE Conferences"
