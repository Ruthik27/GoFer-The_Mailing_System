"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Enhancing Cyber Security Using Audio Techniques: A Public Key Infrastructure for Sound","A. Phipps; K. Ouazzane; V. Vassilev","Cyber Security Research Centre, London Metropolitan University, UK; Cyber Security Research Centre, London Metropolitan University, UK; Cyber Security Research Centre, London Metropolitan University, UK","2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)","9 Feb 2021","2020","","","1428","1436","This paper details the research into using audio signal processing methods to provide authentication and identification services for the purpose of enhancing cyber security in voice applications. Audio is a growing domain for cyber security technology. It is envisaged that over the next decade, the primary interface for issuing commands to consumer internet-enabled devices will be voice. Increasingly, devices such as desktop computers, smart speakers, cars, TV's, phones an Internet of Things (IOT) devices all have built in voice assistants and voice activated features. This research outlines an approach to securely identify and authenticate users of audio and voice operated systems that utilises existing cryptography methods and audio steganography in a method comparable to a PKI for sound, whilst retaining the usability associated with audio and voice driven systems.","2324-9013","978-1-6654-0392-4","10.1109/TrustCom50675.2020.00192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342995","Authentication, Steganography, Two-factor Authentication, Cyber Security, Audio Security","Privacy;Conferences;Public key;Signal processing;Internet of Things;Computer crime;Usability","audio signal processing;cryptography;Internet;Internet of Things;mobile computing;public key cryptography;security of data","audio techniques;public key infrastructure;audio signal;authentication;identification services;voice applications;growing domain;cyber security technology;primary interface;consumer internet-enabled devices;Things devices;voice assistants;voice activated features;cryptography methods;audio steganography;voice driven systems","","","","26","","9 Feb 2021","","","IEEE","IEEE Conferences"
"Enhancing realism in virtual environments by simulating the audio-haptic sensation of walking on ground surfaces","R. Nordahl; S. Serafin; N. C. Nilsson; L. Turchet","Aalborg University Copenhagen Lautrupvang 15, 2750 Ballerup, DK; Aalborg University Copenhagen Lautrupvang 15, 2750 Ballerup, DK; Aalborg University Copenhagen Lautrupvang 15, 2750 Ballerup, DK; Aalborg University Copenhagen Lautrupvang 15, 2750 Ballerup, DK","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","73","74","In this paper we describe an experiment whose goal is to investigate the role of physics-based auditory and haptic feedback provided at feet level to enhance realism in a virtual environment. To achieve this goal, we designed a multimodal virtual environment where subjects could walk on a platform overlooking a canyon. Subjects were asked to visit the environment wearing an head-mounted display and a custom made pair of sandals enhanced with sensors and actuators. A 12-channels surround sound system delivered a soundscape which was consistent with the visual environment. Passive haptics was provided by having a physical wooden platform present in the laboratory. Subjects reported of having a more realistic experience while auditory and haptic feedback are present. However, measured physiological data and post-experimental presence questionnaire do not show significant differences when audio-haptic feedback is provided.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180888","audio-haptic feedback;realism;presence","Haptic interfaces;Footwear;Virtual environments;Sensors;Temperature measurement;Legged locomotion;Actuators","actuators;haptic interfaces;hearing;sensors;virtual reality","realism enhancement;audio-haptic walking sensation;ground surfaces;physics-based auditory feedback;haptic feedback;multimodal virtual environment;sandals;sensors;actuators;12-channels surround sound system;visual environment;passive haptics;physical wooden platform","","8","","6","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Temporal Tile Shaping for spectral gap filling in audio transform coding in EVS","S. Disch; C. Neukam; K. Schmidt","Fraunhofer Institute for Integrated Circuits (IIS), Am Wolfsmantel 33, 91058 Erlangen, Germany; Fraunhofer Institute for Integrated Circuits (IIS), Am Wolfsmantel 33, 91058 Erlangen, Germany; Fraunhofer Institute for Integrated Circuits (IIS), Am Wolfsmantel 33, 91058 Erlangen, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","5873","5877","At low bitrates, next generation audio coders apply waveform preserving transform coding only for the perceptually most relevant parts of the signal. The resulting spectral gaps are filled in the decoder through techniques like Intelligent Gap Filling (IGF). IGF is currently being standardized in MPEG-H 3D-Audio and also in 3GPP Enhanced Voice Service (EVS). In IGF processing, spectral tiles are copied from a spectral source location into a target location and subsequently adapted by parameter steered post-processing to best match relevant properties of the original signal. Important properties include the spectral and temporal envelope. Since IGF operates on Modified Discrete Cosine Transform (MDCT) spectra of rather long time blocks, temporal envelope shaping is not trivial. In this paper, Temporal Tile Shaping (TTS) is presented. TTS is based on linear prediction in the MDCT domain for shaping the temporal structure of the gap filling signal in the target tiles with sub-block granularity. A listening test demonstrates the advantage of the proposed method.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7179098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7179098","Audio Coding;Noise Filling;Temporal Noise Shaping;Intelligent Gap Filling;Enhanced Voice Service","Transform coding;Noise;Codecs;Quantization (signal);Decoding;Bit rate;Transforms","3G mobile communication;audio coding;discrete cosine transforms;signal denoising","temporal tile shaping;spectral gap filling;audio transform coding;EVS;3GPP enhanced voice service;generation audio coders;waveform preserving transform coding;intelligent gap filling;IGF;MPEG-H 3D-audio;spectral source location;target location;parameter steered post-processing;spectral envelope;temporal envelope;modified discrete cosine transform spectra;MDCT domain;subblock granularity","","6","3","18","","6 Aug 2015","","","IEEE","IEEE Conferences"
"Audio bandwidth detection in the EVS codec","V. Eksler; M. Jel√≠nek; W. Jaegers","University of Sherbrooke, VoiceAge Corporation, Montreal, QC, Canada; University of Sherbrooke, VoiceAge Corporation, Montreal, QC, Canada; Fraunhofer IIS Erlangen, Germany","2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","25 Feb 2016","2015","","","488","492","Speech and audio codecs are usually designed such that they encode all the frequency bands of the input signal spectrum. If the higher bands do not contain any perceptually meaningful content, these codecs often do not work optimally as they assign part of the available bit budget to encode these bands. In this paper we describe a bandwidth detection algorithm that determines the effective audio bandwidth of the input signal. This information is used to set the codec to its optimal configuration and consequently increase the coding efficiency for band-limited signals by allocating bits to encode only the useful bandwidth. The presented algorithm has been used in the new codec for Enhanced Voice Services (EVS), recently standardized by 3GPP, but it can be employed in other codecs as well.","","978-1-4799-7591-4","10.1109/GlobalSIP.2015.7418243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7418243","bandwidth detection;band-limited input;speech coding;audio coding;EVS codec","Bandwidth;Codecs;Encoding;Radiation detectors;Bit rate;Switches;Discrete cosine transforms","audio coding;bandlimited signals;speech codecs","audio bandwidth detection;EVS codec;speech codec;audio codec;input signal spectrum frequency band;coding efficiency;band-limited signals;enhanced voice services;EVS;3GPP","","","2","6","","25 Feb 2016","","","IEEE","IEEE Conferences"
"Deep Audio-Visual Speech Separation with Attention Mechanism","C. Li; Y. Qian","Shanghai Jiao Tong University,MoE Key Lab of Artificial Intelligence SpeechLab,Shanghai,China; Shanghai Jiao Tong University,MoE Key Lab of Artificial Intelligence SpeechLab,Shanghai,China","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","7314","7318","Previous work shows that audio-visual fusion is a practical approach to deal with the speech separation task in the cocktail party problem. In this paper, we explore a better strategy to utilize visual representations with the attention mechanism. Compared to the previous baseline only using one visual stream of the target speaker, both speaker-dependent visual streams in the mixed audio are fed into the model, and it also predicts two separated speech streams simultaneously. To further enhance the performance, the attention mechanism is designed on the audio-visual speech separation architecture. The results show that the proposed approach works well in audio-visual speech separation. Our best model achieves an obvious and consistent improvement in speech separation when compared to the traditional method only using the target speaker visual stream.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054180","Audio-Visual;Speech Separation;Multimodal;Attention mechanism","Visualization;Conferences;Speech enhancement;Signal processing;Predictive models;Acoustics;Task analysis","audio signal processing;audio-visual systems;source separation;speaker recognition","cocktail party problem;visual representations;attention mechanism;speaker-dependent visual streams;mixed audio;separated speech streams;audio-visual speech separation architecture;target speaker visual stream;deep audio-visual speech separation;audio-visual fusion;speech separation task","","4","","27","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A Robust Combined Audio and Video Watermark Algorithm Against Cinema Piracy","H. Kelkoul; Y. Zaz; H. Tribak; G. Schaefer","Faculty of Science, University of Abdelmalek Essaadi, Tetouan, Morocco; Faculty of Science, University of Abdelmalek Essaadi, Tetouan, Morocco; Faculty of Science, University of Abdelmalek Essaadi, Tetouan, Morocco; Faculty of Science, University of Abdelmalek Essaadi, Tetouan, Morocco","2018 6th International Conference on Multimedia Computing and Systems (ICMCS)","8 Nov 2018","2018","","","1","4","The current trend in Moroccan digital cinema is to make feature films available online. In order to counter illegal distribution of media files in Morocco, this paper suggests an effective algorithm that combines processing of both audio and video streams. We extract an audio fingerprint pattern which is embedded in video frames as a watermark using the discrete wavelet transform. The two data streams are then synchronized using a time code, and the final multimedia protected content is exported in JPEG2000 format, which is the format used for Digital Cinema Package (DCP) in Morocco. Experimental results show that the proposed algorithm provides a high level of robustness, while the use of watermarks in a combination of audio and video streams allows to enhance the security of multimedia content.","2472-7652","978-1-5386-6220-5","10.1109/ICMCS.2018.8525979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525979","Multimedia processing;secrurity protection;digital watermarking;audio fingerprinting;discrete wavelet transform","Watermarking;Motion pictures;Discrete wavelet transforms;Streaming media;Signal processing algorithms","audio watermarking;cinematography;data compression;discrete wavelet transforms;image coding;video coding;video streaming;video watermarking","robust combined audio watermark;digital cinema package;multimedia protected content;audio stream;discrete wavelet transform;time code;media files;illegal distribution;Moroccan digital cinema;cinema piracy;video watermark algorithm;JPEG2000 format;data streams;video frames;audio fingerprint pattern;video streams","","","","13","","8 Nov 2018","","","IEEE","IEEE Conferences"
"Spectral envelope reconstruction via IGF for audio transform coding","C. R. Helmrich; A. Niedermeier; S. Disch; F. Ghido","International Audio Laboratories Erlangen, Am Wolfsmantel 33, 91058, Germany; Fraunhofer Institut f√ºr Integrierte Schaltungen (IIS), Am Wolfsmantel 33, 91058 Erlangen, Germany; Fraunhofer Institut f√ºr Integrierte Schaltungen (IIS), Am Wolfsmantel 33, 91058 Erlangen, Germany; International Audio Laboratories Erlangen, Am Wolfsmantel 33, 91058, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","389","393","In low-bitrate audio coding, modern coders often rely on efficient parametric techniques to enhance the performance of the waveform preserving transform coder core. While the latter features well-known perceptually adapted quantization of spectral coefficients, parametric techniques reconstruct the signal parts that have been quantized to zero by the encoder to meet the low-bitrate constraint. Large numbers of zeroed spectral values and especially consecutive zeros constituting gaps often lead to audible artifacts at the decoder. To avoid such artifacts the new 3GPP Enhanced Voice Services (EVS) coding standard utilizes noise filling and intelligent gap filling (IGF) techniques, guided by spectral envelope information. In this paper the underlying considerations of the parametric energy adjustment and transmission in EVS and its relation to noise filling, IGF, and tonality preservation are presented. It is further shown that complex-valued IGF envelope calculation in the encoder improves the temporal energy stability of some signals while retaining real-valued decoder-side processing.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7177997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177997","Audio coding;noise shaping;parametric","Encoding;Decoding;Noise;Transforms;Quantization (signal);Codecs;Transform coding","audio coding;codecs","spectral envelope reconstruction;IGF;audio transform coding;low-bitrate audio coding;modern coders;spectral coefficients;3GPP;enhanced voice services coding standard;noise filling;intelligent gap filling;spectral envelope information;real-valued decoder-side processing","","9","2","14","","6 Aug 2015","","","IEEE","IEEE Conferences"
"Dynamic stochastic resonance-based watermark extraction from audio signals in SVD domain","R. K. Jha; O. Krishna; K. Aizawa","PDPM Indian Institute of Information Technology Jabalpur, 482001, India; PDPM Indian Institute of Information Technology Jabalpur, 482001, India; The University of Tokyo, Japan. Department of Info. & Comm. Engg.","2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)","18 Oct 2012","2012","","","2684","2688","In this paper a dynamic stochastic resonance (DSR)-based watermark extraction technique from audio signal using singular value decomposition (SVD) has been presented. Watermark embedding has been done by weighted addition of the binary watermark in the singular values of the audio signal. DSR has been used in the extraction process to improve the authenticity of the extracted watermark by utilizing the noise or degradation introduced during different signal processing attacks. DSR is an iterative process that tunes the coefficient of possibly attacked watermarked audio signal so that effect of noise is suppressed and hidden information is enhanced. An adaptive optimization procedure has been adopted for selection of bistable parameters to achieve maximum correlation coefficient under minimum computational complexity. Resilience of this technique has been tested in presence of various signal processing attacks. Using proposed technique robust extraction of watermark is obtained without trading off the audibility of audio signal. Comparison with plain SVD-based, DWT-based and DCT-based techniques reflects that the proposed DSR-based audio watermarking scheme gives remarkably better performance in terms of correlation between original and extracted watermarks.","2076-1465","978-1-4673-1068-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6334139","Audio Watermarking;Singular Value Decomposition;Dynamic Stochastic Resonance;Noise","Watermarking;Robustness;Signal to noise ratio;Correlation;Speech;Stochastic resonance","audio watermarking;computational complexity;feature extraction;iterative methods;optimisation;singular value decomposition;stochastic processes","dynamic stochastic resonance-based watermark extraction;SVD domain;DSR-based watermark extraction technique;singular value decomposition;binary watermark;signal processing attacks;iterative process;watermarked audio signal;adaptive optimization procedure;maximum correlation coefficient;minimum computational complexity;DCT-based techniques;DWT-based techniques;DSR-based audio watermarking scheme","","","","12","","18 Oct 2012","","","IEEE","IEEE Conferences"
"A flexible architecture of real-time audio transmission to heterogeneous devices for surveillance system","Y. Cheng; H. Lin; Y. Yeh","Telecom Laboratories, Chunghwa Telecom Co., Ltd., Taoyuan, Taiwan, ROC; Telecom Laboratories, Chunghwa Telecom Co., Ltd., Taoyuan, Taiwan, ROC; Telecom Laboratories, Chunghwa Telecom Co., Ltd., Taoyuan, Taiwan, ROC","The 16th Asia-Pacific Network Operations and Management Symposium","29 Dec 2014","2014","","","1","4","This paper presents a software architecture for audio transmission to network cameras while integrating multiple types of cameras from different manufacturers under a Web-based surveillance system. Adding audio streams in surveillance system will enhance the capabilities for remote monitoring. This architecture offers a plug-and-play service of audio transmission to cameras over the network for numerous users. It not only simplifies but also facilitates the integration process of heterogeneous devices.","","978-4-88552-288-8","10.1109/APNOMS.2014.6996108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996108","Surveillance system;audio transmission;network camera","Servers;Cameras;Surveillance;Relays;Computer architecture;Protocols;Software","audio streaming;Internet;software architecture;surveillance;video streaming","flexible architecture;real-time audio transmission;heterogeneous devices;software architecture;network cameras;Web-based surveillance system;audio streams;remote monitoring;plug-and-play service","","1","","6","","29 Dec 2014","","","IEEE","IEEE Conferences"
"Audio-visual speech recognition in noisy audio environments","K. Paleƒçek; J. Chaloupka",The Institute of Information Technology and Electronics at the Technical University of Liberec; The Institute of Information Technology and Electronics at the Technical University of Liberec,"2013 36th International Conference on Telecommunications and Signal Processing (TSP)","30 Sep 2013","2013","","","484","487","It is a well-known fact that the visual part of speech can improve the resulting recognition rate mainly in noisy conditions. Main goal of this work is to find a set of visual features which would be possible to use in our audio-visual speech recognition systems. Discrete Cosine Transform (DCT) and Active Appearance Model (AAM) based visual features are extracted from visual speech signals, enhanced by a simplified variant of Hierarchical Linear Discriminant Analysis (HiLDA) and normalized across speakers. The visual features are then combined with standard MFCC audio features by the middle fusion method. The results from audio-visual speech recognition are compared with the results from experiments where the log-spectra minimum mean square error and multiband spectral subtraction methods for reducing additive noise in the audio signal are used.","","978-1-4799-0404-4","10.1109/TSP.2013.6613979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613979","AAM;audio-visual speech recognition;HiLDA;visual speech feature extraction;speech enhancement","Visualization;Speech recognition;Speech;Feature extraction;Discrete cosine transforms;Shape;Active appearance model","audio-visual systems;discrete cosine transforms;feature extraction;image fusion;image recognition;mean square error methods;speech enhancement;speech recognition","audio-visual speech recognition;noisy audio environments;visual features;discrete cosine transform;DCT;active appearance model;AAM;visual feature extraction;visual speech signals;hierarchical linear discriminant analysis;HiLDA;MFCC audio features;middle fusion method;log-spectra minimum mean square error;multiband spectral subtraction;additive noise","","6","","15","","30 Sep 2013","","","IEEE","IEEE Conferences"
"A Novel Enhanced LSB Algorithm for High Secure Audio Steganography","M. Mustafa; M. Mahmoud; H. Tagelsir; I. Elshoush","Computer Science Department, University of Khartoum, Sudan; Computer Science Department, University of Khartoum, Sudan; Computer Science Department, University of Khartoum, Sudan; Computer Science Department, University of Khartoum, Sudan","2018 10th Computer Science and Electronic Engineering (CEEC)","28 Mar 2019","2018","","","125","130","This paper proposes a novel model to hide the very secret and sensitive information within an audio file. The proposed model consists of three stages, the text is first compressed using the Huffman algorithm then encrypted using AES algorithm and finally hide using the novel LSB-Block algorithm. A novel proposed mechanism, Binaries of Message Size Encoding (BMSE), were performed before the hiding process to produce a key, which is used in the hiding process in the proposed enhanced LSB-Block algorithm. The model was applied using the MATLAB program and tested using the Mean Error Square (MSE) operators and the Peak Signal to Noise Ratio (PSNR). Different comparisons were made and the results verified the efficiency and effectiveness of the proposed model.","","978-1-5386-7275-4","10.1109/CEEC.2018.8674230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674230","Audio Steganography;Least Significant Bit (LSB);AES;Huffman algorithm","Cryptography;Mathematical model;Indexes;Agriculture;Computer science;Computational modeling","audio coding;block codes;data compression;Huffman codes;mean square error methods;steganography","enhanced LSB-Block algorithm;Mean Error Square operators;high secure audio steganography;secret information;sensitive information;audio file;Huffman algorithm;AES algorithm;Message Size Encoding;LSB-Block algorithm;enhanced LSB algorithm","","","","17","","28 Mar 2019","","","IEEE","IEEE Conferences"
"Research on algorithm of audio level compressor","Sun Yuhang; Li Shanshan","Communication University of China, Beijing, China; Communication University of China, Beijing, China","2016 2nd IEEE International Conference on Computer and Communications (ICCC)","11 May 2017","2016","","","1957","1960","A audio compressor is an important part of a audio processing system. The compression algorithm designed in this paper will be applied to audio compressor in the digital audio broadcasting transmitter. In this paper, an effective algorithm for dynamic control of the gain by taking mean square value is proposed, and two different audio signal from two channel processing schemes will be compared to get better one on the impact of compression. Then the algorithm is evaluated by the effect of compression of signal amplitude in the MATLAB simulation, and a scheme selected that signal is firstly dealt with to enhance the effect of the dual channel stereo and then is compressed is more suitable for the two channel audio compression from two schemes.","","978-1-4673-9026-2","10.1109/CompComm.2016.7925043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7925043","compressor;algorithm;mean square value;gain;scheme","Heuristic algorithms;Sun","audio signal processing;compressors;data compression","audio level compressor;audio processing system;compression algorithm;digital audio broadcasting transmitter;dynamic control;mean square value;audio signal;channel processing schemes;signal amplitude;MATLAB simulation;dual channel stereo;channel audio compression","","","","5","","11 May 2017","","","IEEE","IEEE Conferences"
"Robust SVD-Based Audio Watermarking Scheme With Differential Evolution Optimization","B. Lei; I. Y. Soon; E. Tan","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Medicine, Shenzhen University, P.R.China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Audio, Speech, and Language Processing","17 Oct 2013","2013","21","11","2368","2378","In this paper, a robust audio watermarking scheme based on singular value decomposition (SVD) and differential evolution (DE) using dither modulation (DM) quantization algorithm is proposed. Two novel SVD-based algorithms, lifting wavelet transform (LWT)-discrete cosine transform (DCT)-SVD and discrete wavelet transform (DWT)-DCT-SVD, are developed for audio copyright protection. In our method, LWT\DWT is first applied to decompose the host signal and obtain the corresponding approximate coefficients followed by DCT to take advantage of ‚Äúenergy compaction‚Äù property. SVD is further performed to acquire the singular values and enhance the robustness of the scheme. The adaptive DM quantization is adopted to quantize the singular values and embed the watermark. To withstand desynchronization attacks, synchronization code is inserted using audio statistical characteristics. Furthermore, the conflicting problem of robustness and imperceptibility is effectively resolved by the DE optimization. Simulation results demonstrate that both the LWT-DCT-SVD and DWT-DCT-SVD methods not only have good imperceptibility performance, but also resist general signal processing, hybrid and desynchronization attacks. Compared with the previous DWT-DCT, support vector regression (SVR)-DWT-DCT and DWT-SVD methods, our method obtains more robustness against the selected attacks.","1558-7924","","10.1109/TASL.2013.2277929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583307","Audio watermarking;DE;DM;DWT-DCT-SVD;LWT-DCT-SVD;synchronization","Watermarking;Synchronization;Discrete wavelet transforms;Robustness;Vectors","audio watermarking;copy protection;copyright;differential equations;discrete cosine transforms;discrete wavelet transforms;optimisation;singular value decomposition","robust SVD-based audio watermarking scheme;differential evolution optimization;singular value decomposition;differential evolution;DE;dither modulation quantization algorithm;DM quantization algorithm;lifting wavelet transform-discrete cosine transform SVD algorithm;LWT DCT SVD algorithm;discrete wavelet transform DCT SVD algorithm;DWT-DCT SVD algorithm;audio copyright protection;energy compaction property;adaptive DM quantization;desynchronization attacks;synchronization code;audio statistical characteristics;DE optimization;imperceptibility performance;general signal processing;support vector regression;SVR-DWT-DCT method","","66","","30","","21 Aug 2013","","","IEEE","IEEE Journals"
"Enhanced LSB technique for audio steganography","H. Kumar; Anuradha","Krishna Engineering College, Ghaziabad, India; MIET, Meerut, India","2012 Third International Conference on Computing, Communication and Networking Technologies (ICCCNT'12)","31 Dec 2012","2012","","","1","4","The idea of this paper is to invent a new strategy in Steganography to get the minimum effect in audio which is used to hide data into it. ‚ÄúProgress always involves risk‚Äù Fredrick Wilcox observed that technological progress of computer science and the Internet altered the way we lived, and will continue to cast our life[1] . In this paper we have presented a Steganography method of embedding text data in an audio file. The basic approach behind this paper is to provide a good, well-organized method for hiding the data and sent to the destination in safer manner. In the proposed technique first the audio file is sampled and then appropriate bit is modified. In selected sample one bit is modified at least significant bit .The remaining bits may be used but it may be cause noise. We have attempted to provide an overview, theoretical framework about audio Steganography techniques and a novel approach to hide data in an audio using least significant bit (LSB).","","","10.1109/ICCCNT.2012.6395978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395978","Steganography;LSB;Human Auditory system;WAV;Spectrum","Resistance;Cryptography;Algorithm design and analysis;Encoding;Decoding","audio coding;steganography;text analysis","LSB technique;audio steganography;data hiding;computer science;Internet;text data embedding;audio file;least significant bit","","15","","11","","31 Dec 2012","","","IEEE","IEEE Conferences"
"Arithmetic coding of speech and audio spectra using tcx based on linear predictive spectral envelopes","T. B√§ckstr√∂m; C. R. Helmrich","International Audio Laboratories Erlangen1, Friedrich-Alexander University (FAU), Germany; International Audio Laboratories Erlangen1, Friedrich-Alexander University (FAU), Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","5127","5131","Unified speech and audio codecs often use a frequency domain coding technique of the transform coded excitation (TCX) type. It is based on modeling the speech source with a linear predictor, spectral weighting by a perceptual model and entropy coding of the frequency components. While previous approaches have used neighbouring frequency components to form a probability model for the entropy coder of spectral components, we propose to use the magnitude of the linear predictor to estimate the variance of spectral components. Since the linear predictor is transmitted in any case, this method does not require any additional side info. Subjective measurements show that the proposed methods give a statistically significant improvement in perceptual quality when the bit-rate is held constant. Consequently, the proposed method has been adopted to the 3GPP Enhanced Voice Services speech coding standard.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7178948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178948","speech and audio coding;frequency domain coding;arithmetic coding","Speech;Codecs;Predictive models;Speech coding;Standards;Transform coding","arithmetic codes;audio coding;entropy codes;frequency-domain analysis;speech codecs;speech coding;statistical analysis;transform coding","speech arithmetic coding;audio spectra arithmetic coding;TCX;linear predictive spectral envelope;unified speech codec;unified audio codec;frequency domain coding technique;transform coded excitation;speech source model;linear predictor;spectral weighting;perceptual model;frequency component entropy coding;probability model;spectral component entropy coder;perceptual quality;statistical bit rate;3GPP enhanced voice service speech coding standard","","10","2","9","","6 Aug 2015","","","IEEE","IEEE Conferences"
"A Neuro-C4.5 Paradigm for Audio Steganogram Detection Based on Asymmetric Cost of False Errors","S. Geetha; S. Muthuramalingam","Sch. of Comput. Sci. & Eng., VIT Univ., Chennai, India; Dept. of Inf. Technol., Thiagarajar Coll. of Eng., Madurai, India","2014 3rd International Conference on Eco-friendly Computing and Communication Systems","20 Aug 2015","2014","","","242","245","This paper proposes an Audio Quality Metrics (AQM) based steg analysis for detecting audio steganograms. Primarily two contributions are made to achieve superior detection rates of the proposed steganalyser. First, an effective learning algorithm is employed for audio steg analysis, neuro C4.5, which possesses good comprehensibility and generalization ability. Second, the asymmetric costs of false positive and negative errors are investigated to enhance the steganalyser's performance. Empirical results show that the neuro-C4.5 model, designed based on the asymmetric costs of false negative and false positive errors proves to be effective.","","978-1-4799-7002-5","10.1109/Eco-friendly.2014.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7209000","Audio Steganalysis;Audio Quality Metrics;Neuro C4.5 algorithm;False Error;Asymmetric cost;Information Forensics","Communication systems","audio coding;learning (artificial intelligence);steganography","neuro-C4.5 paradigm;audio steganogram detection;asymmetric false errors cost;audio quality metrics;AQM;learning algorithm;comprehensibility ability;generalization ability;false negative error;false positive error","","","","19","","20 Aug 2015","","","IEEE","IEEE Conferences"
"Kernel weighted Fisher sparse analysis on multiple maps for audio event recognition","Y. Chin; B. Chen; J. Wang","Dept. of Computer Science & Information Engineering, National Central University, Taoyuan, Taiwan; School of Information Technology, Monash University, Malaysia; Dept. of Computer Science & Information Engineering, National Central University, Taoyuan, Taiwan","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","6010","6014","This work presents a novel approach for audio event recognition. The approach develops a weighted kernel fisher sparse analysis method based on multiple maps. The proposed method consists of maps extraction and kernel weighted Fisher sparse analysis. Two maps are firstly extracted from each audio file, i.e. scale-frequency map and damping-frequency map. The scale and frequency of the Gabor atoms are extracted to construct a scale-frequency map. On the other hand, the damping-frequency map is generated according to the frequency and damping factor of damped atoms. Gabor atoms can be utilized to model human auditory perception, and the damped atoms can be used to model commonly observed damped oscillations in natural signals. This work fuses the advantages of these two dictionaries to improve the performance of the system. During the recognition stage, this work constructs a kernel sparse representation-based classifier via the proposed kernel weighted Fisher sparse analysis to enhance separability. The proposed kernel weighted Fisher sparse analysis combines sparse representation with heteroscedastic kernel weighted discriminant analysis (HKWDA), which is useful for providing a discriminative recognition of audio events because a weighted pairwise Chernoff criterion is utilized in the kernel space. Experiments on a 20-class audio event database indicate that the proposed approach can achieve an accuracy rate of 82.70%. Also, integrating the scale-frequency map with MFCCs increases the accuracy rate to 87.70%.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953310","Kernel weighted Fisher sparse analysis;scale-frequency map;damping-frequency map;kernel sparse classification;audio event classification","Kernel;Dictionaries;Mel frequency cepstral coefficient;Matching pursuit algorithms;Damping;Oscillators;Speech","audio signal processing;sparse matrices","Kernel weighted Fisher sparse analysis;audio event recognition;maps extraction;audio file;scale-frequency map;damping-frequency map;Gabor atoms;human auditory perception;recognition stage;kernel sparse representation-based classifier;kernel weighted Fisher sparse analysis;heteroscedastic kernel weighted discriminant analysis","","","","21","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Secure steganography in audio using inactive frames of VoIP streams","R. Roselinkiruba; R. Balakirshnan","Department of TIFAC-CORE in Pervasive Computing Technologies Velammal Engineering College Chennai, India; Department of TIFAC-CORE in Pervasive Computing Technologies Velammal Engineering College Chennai, India","2013 IEEE Conference on Information & Communication Technologies","15 Jul 2013","2013","","","491","495","Steganography is a data hiding process in which information is secured, while transferring data from sender to receiver. In audio steganography, encoding process is carried nut through inactive frames of low bit rate audio streams by performing iLBC (internet Low Bit rate Codec). This methodology can be used in applications such as VoIP (Voice Over Internet Protocol), streaming audio, archival and messaging. Traditionally, data embedding is carried out in the inactive frames rather than the active frame of streams; that is inactive frame has large embedding capacity. In addition VAD (Voice Activity Detection) algorithm is used for detecting inactive frames. The concealment of analysis is encoded by iLBC, that supports two basic frame lengths, giving a bit-rate of 13.3 kbps with an encoding frame length of 30 ms and 15.2 kbps with an encoding frame length of 20 nis . To enhance security in steganography PCC (Parabolic Curve Cryptography) algorithm is implemented.","","978-1-4673-5758-6","10.1109/CICT.2013.6558145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6558145","inactive frames;stegarrography;iLBC;audio streams;VoIP","Speech;Cryptography;Internet;IP networks;Speech coding;Codecs;Spectrogram","audio coding;audio streaming;codecs;data privacy;embedded systems;Internet telephony;steganography","inactive frame detection;VoIP streaming;data hiding process;information security;data transfer;audio steganography;encoding process;audio streaming;iLBC;Internet low bit rate codec;voice over Internet protocol;data embedding;VAD algorithm;voice activity detection;encoding frame length;PCC;parabolic curve cryptography;bit rate 13.3 kbit/s;time 30 ms;bit rate 15.2 kbit/s;time 20 ms","","1","","13","","15 Jul 2013","","","IEEE","IEEE Conferences"
"Fast Algorithms for Low-Delay SBR Filterbanks in MPEG-4 AAC-ELD","R. K. Chivukula; Y. A. Reznik; V. Devarajan; M. Jayendra-Lakshman","Qualcomm Inc., San Diego, CA, USA; Qualcomm Inc., San Diego, CA, USA; Department of Electrical Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Electrical Engineering, The University of Texas at Arlington, Arlington, TX, USA","IEEE Transactions on Audio, Speech, and Language Processing","23 Jan 2012","2012","20","3","1022","1031","The MPEG committee has recently completed development of a new audio coding standard ‚ÄúMPEG-4 Advanced Audio Coding-Enhanced Low Delay‚Äù (AAC-ELD). AAC-ELD is targeted towards high-quality, full-duplex communication applications such as audio and video conferencing. AAC-ELD uses low delay spectral band replication (LD-SBR) technology together with a low delay AAC core encoder to achieve high coding efficiency and low algorithmic delays. In this paper, we present fast algorithms for computing LD-SBR filterbanks in AAC-ELD. The proposed algorithms map complex exponential modulation portion of the filterbanks to discrete cosine transforms of types IV and II. Our proposed mapping also allows to merge some multiplications with the windowing stage that precedes or succeeds the modulation step. This further reduces computational complexity. Our presentation includes detailed explanation and flow-graphs of the algorithms, complexity analysis, and comparisons with alternative implementations.","1558-7924","","10.1109/TASL.2011.2170971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6036151","Advanced audio coding (AAC);discrete cosine transform (DCT);DCT-IV;factorization;fast algorithms;filterbank;low delay audio coding;Moving Picture Experts Group (MPEG);spectral band replication (SBR)","Delay;Algorithm design and analysis;Transform coding;Decoding;Modulation;Audio coding;Speech","audio coding;channel bank filters;computational complexity;discrete cosine transforms;graph theory;teleconferencing","low-delay SBR filterbanks;MPEG-4 AAC-ELD;advanced audio coding-enhanced low delay;full-duplex communication applications;audio conferencing;video conferencing;low delay spectral band replication technology;high coding efficiency;low algorithmic delays;complex exponential modulation;discrete cosine transforms;DCT;windowing stage;computational complexity;flow-graphs","","8","1","24","","10 Oct 2011","","","IEEE","IEEE Journals"
"Recipes for Creating and Delivering Next-Generation Broadcast Audio","S. Mehta; T. Onders; J. Riedmiller",Dolby Laboratories; Dolby Laboratories; Dolby Laboratories,"SMPTE 2015 Annual Technical Conference and Exhibition","8 Feb 2016","2015","","","1","12","Next generation audio systems and codecs allow content creators to engage their audiences with more accessible, immersive and personalized sound experiences. While these systems provide a great deal of flexibility in the amount of audio that can be delivered and the amount of control given to consumers, the industry can benefit from a set of pre-defined operating profiles for the first incarnations of next-generation audio. ‚Äî This paper provides a practical overview of some basic audio profiles and mechanisms for delivering stereo, surround, personalized and immersive content in next-generation audio systems. Legacy stereo and surround content benefits from new system features including enhanced loudness management and improved dialogue intelligibility for pre-mixed sources. Personalized and immersive content can be created and delivered in ways that ensure that every consumer receives a premium experience across every device. New delivery systems and encoders ensure seamless and robust switching between different content types and layouts.","","978-1-61482-956-0","10.5594/M001655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399643","Next-generation audio;immersive audio;personalized audio;accessible audio;AC-4;audio mixing;object-based audio;audio objects;loudness;Dolby;dialogue enhancement;personalization;3D audio;Dolby Atmos","","","","","","1","3","","8 Feb 2016","","","SMPTE","SMPTE Conferences"
"AVISION Audio and visual attention models applied to 2D and 3D audio-visual content","N. Just; M. Laabs; E. Unver; B. Gunel; S. Worrall; A. M. Kondoz","Institut fuer Rundfunktechnik, Munich, Germany; Institut fuer Rundfunktechnik, Munich, Germany; University of Surray, Guildford, Surrey, United Kingdom; University of Surray, Guildford, Surrey, United Kingdom; University of Surray, Guildford, Surrey, United Kingdom; University of Surray, Guildford, Surrey, United Kingdom","2011 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","14 Jul 2011","2011","","","1","6","Within this paper a highly flexible approach for audio and visual attention modeling is presented. The developed system aims to be widely adaptable for different application scenarios within multimedia processing and coding. Possible use cases are presented and their influence on the system concept is shown. Furthermore the development of an attention model within the EU-funded research project DIOMEDES is described. This project focuses on developing a system for hybrid delivery of 3D stereoscopic and multi-view content to the homes through multiple transmission paths. The attention model, which is based on the framework presented, is used to enhance the content encoding process. This publication gives an overview over system design aspects as well as algorithms used for attention modeling.","2155-5052","978-1-61284-122-9","10.1109/BMSB.2011.5954949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5954949","3D;multi-view;audio/visual attention;audio/video processing;content adaption","Visualization;Feature extraction;Adaptation models;Encoding;Filtering algorithms;Three dimensional displays;Speech","audio coding;multimedia computing;stereo image processing;video coding","audio attention models;visual attention models;2D audio-visual content;3D audio-visual content;multimedia processing;multimedia coding;EU-funded research project;DIOMEDES;3D stereoscopic content;multiview content;multiple transmission paths","","","","16","","14 Jul 2011","","","IEEE","IEEE Conferences"
"N-gram extension for bag-of-audio-words","S. Pancoast; M. Akbacak","Speech Technology and Research Lab, SRI International, Menlo Park, CA, USA; Microsoft, Sunnyvale, CA, USA","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","778","782","Bag-of-audio-words is one of the most frequently used methods for incorporating an audio component into multimedia event detection and related tasks. A main criticism of the method, however, is that it ignores context. Each ‚Äúword‚Äù is considered in isolation, ignoring its neighbors. We address this issue by representing the document by its audio word N-grams. Unlike words from natural language, audio words are generated by clustering algorithms where the number of clusters is specified by the researcher. We therefore also explore how the performance of the N-gram representation varies with codebook size. With this enhanced representation, we find the average probability of miss noticeably decreases when evaluated on TRECVID 2011 and 2012 datasets, indicating clear improvements on the multimedia event detection task.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6637754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637754","Bag-of-audio-words;N-gram models;multimedia event detection","Histograms;Vectors;Multimedia communication;Event detection;Videos;Natural languages;NIST","audio systems;codes;multimedia communication;pattern clustering;probability","bag-of-audio-word generation;multimedia event detection;document representation;audio word N-gram representation extension;natural language;clustering algorithm;codebook;average probability;TRECVID 2011 dataset;TRECVID 2012 dataset","","2","","11","","21 Oct 2013","","","IEEE","IEEE Conferences"
"Audio Replay Spoof Attack Detection by Joint Segment-Based Linear Filter Bank Feature Extraction and Attention-Enhanced DenseNet-BiLSTM Network","L. Huang; C. Pun","Department of Computer and Information Science, University of Macau, Macau, China; Department of Computer and Information Science, University of Macau, Macau, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","23 Jun 2020","2020","28","","1813","1825","Most automatic speaker verification (ASV) systems are vulnerable to various spoofing attacks. In recent years, there have been many methods were proposed for detecting spoofing attacks in ASV, and significant progress has been made. However, current methods have shown little improvements in replay spoof attack detection as they lack a more suitable model for replay detection. To address this issue, in this article, we propose a novel model based on attention-enhanced DenseNet-BiLSTM network and segment-based linear filter bank features. First, silent segments are selected from each speech signal by using a short-term zero-crossing rate and energy. If the total duration of silent segments only contains a very limited amount of data, the decaying tails will be selected instead. Second, the linear filter bank features are extracted from the selected segments in the relatively high-frequency domain. Finally, an attention-enhanced DenseNet-BiLSTM architecture which can avoid the problems of overfitting is built. To validate this model, we used two datasets, including BTAS2016 and ASVspoof2017. Experiments show that using the attention-enhanced DenseNet-BiLSTM model with the segment-based linear filter bank feature achieves the best performance. Compared with the baseline system based on constant Q cepstral coefficient and Gaussian mixture model (GMM), the proposed model can produce a relative improvement of 91.68% and 74.04% on the two data sets respectively.","2329-9304","","10.1109/TASLP.2020.2998870","Universidade de Macau(grant numbers:MYRG2018-00035-FST,MYRG2019-00086-FST); Science and Technology Development Fund, Macau SAR(grant numbers:041/2017/A1,0019/2019/A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107432","Attack detection;attention-enhanced;denseNet-BiLSTM network;linear filter bank feature;replay spoof","Feature extraction;Speech processing;Mel frequency cepstral coefficient;Deep learning;Speech recognition;Task analysis;Filter banks","channel bank filters;feature extraction;neural nets;security of data;speaker recognition","Q cepstral coefficient;ASVspoof2017 datasets;BTAS2016 datasets;high-frequency domain;speech signal;audio replay spoof attack detection;joint segment-based linear filter bank feature extraction;Gaussian mixture model;attention-enhanced DenseNet-BiLSTM model;attention-enhanced DenseNet-BiLSTM architecture;short-term zero-crossing rate;attention-enhanced DenseNet-BiLSTM network;ASV systems;automatic speaker verification systems","","1","","59","IEEE","3 Jun 2020","","","IEEE","IEEE Journals"
"Multi-model Emotion Expression Recognition for Lip Synchronization","S. A. Al-agha; H. H. Saleh; R. F. Ghani","University of Technology,Dept. of Electrical Engineering,Baghdad,Iraq; University of Technology,Dept. of Computer Science,Baghdad,Iraq; University of Technology,Dept. of Computer Science,Baghdad,Iraq","2020 1st. Information Technology To Enhance e-learning and Other Application (IT-ELA","13 Nov 2020","2020","","","171","177","Lip synchronization problem is a significant requirement in the multimedia world. The synchronization plan is in charge of guaranteeing that the sound and video streams are synchronized after handling. In recent years, there is a great deal of research, which was conducted on the issue of employing the recognition operation of emotion expressions, in the process of identifying and finding a solution to the problem of synchronization. This paper is based on the concept of recognizing the problem of synchronization in the multi-models audio/video of emotion expressions for non-synchronizing 3D video film stereoscopic. The proposed work is divided into two-stage: the recognition of audio expressions and the recognition of visual information expressions, with four basic emotion expressions: Anger, Happiness, Sadness, and Surprise. Multi-Layer Perceptron Back Propagation network is used for voice classification and depth image classification. Absolute Distance Differences is used for Intensity Frames of 3D Video (Geometric-based Feature) classification. The classification rate for the isolated audio signal is 90%. The classification rate for the geometric-based process of intensity image, plus depth image for different features of 3D video film is 80%. The classification rate for the geometric-based process of intensity image plus depth image for curvelet features of 3D video film is 82%. The recognition rate for the whole proposed system (audio plus video with curvelet features for depth image) is 80%.","","978-1-7281-8233-9","10.1109/IT-ELA50150.2020.9253118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253118","Multi-model Recognition;Emotion Expression;Lip Sync. Audio Emotion Recognition;Video Emotion Recognition","Training;Emotion recognition;Visualization;Three-dimensional displays;Face recognition;Lips;Synchronization","audio signal processing;backpropagation;curvelet transforms;emotion recognition;feature extraction;geometry;image classification;multilayer perceptrons;multimedia systems;stereo image processing;synchronisation;voice activity detection","multimodel emotion expression recognition;lip synchronization;multimedia world;video streams;emotion expression recognition;multilayer perceptron;voice classification;nonsynchronization 3D video film stereoscopic;audio expression recognition;visual information expression recognition;3D video classification;geometric-based feature;absolute distance differences;backpropagation network","","","","9","","13 Nov 2020","","","IEEE","IEEE Conferences"
"Direct-ambient decomposition and upmix of surround signals","A. Walther; C. Faller","√âcole Polytechnique F√©d√©rale de Lausanne, EPFL-IC-LCAV, Station 14, 1015, Switzerland; √âcole Polytechnique F√©d√©rale de Lausanne, EPFL-IC-LCAV, Station 14, 1015, Switzerland","2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","17 Nov 2011","2011","","","277","280","Various direct-ambient signal decompositions, applicable to two-channel stereophonic signals, have been proposed previously. Strategies to enhance these decompositions for multi-channel surround audio signals are not obvious. A method is proposed, which estimates direct and ambient signal components in a downmix of a given surround signal. Those estimates are then used to compute filters to obtain direct and ambient surround signals. Approaches on how to use the decomposed signals for upmixing of surround audio signals in two and three dimensions are also discussed.","1947-1629","978-1-4577-0693-6","10.1109/ASPAA.2011.6082279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082279","multi-channel audio;upmix;3D upmix;direct-ambient decomposition","Loudspeakers;Transient analysis;Spectrogram;Estimation;Conferences;Signal resolution","audio equipment;audio signal processing","direct-ambient decomposition;surround signals upmix;two-channel stereophonic signals;multichannel surround audio signals;ambient signal components","","5","12","8","","17 Nov 2011","","","IEEE","IEEE Conferences"
"Enhanced Method of Audio Coding Using CNN-Based Spectral Recovery with Adaptive Structure","S. -H. Shin; S. K. Beack; W. Lim; H. Park","Kwangwoon University,Seoul,Korea; Electronics and Telecommunication Research Institute,Daejeon,Korea; Electronics and Telecommunication Research Institute,Daejeon,Korea; Kwangwoon University,Seoul,Korea","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","351","355","A process of spectral recovery can enhance the performance of transform-based audio coding by transmitting only a portion of spectral data and recovering the missing spectral data in the decoder. This study proposes an enhanced method of audio coding based on spectral recovery with an adaptive structure that yields improved sound quality compared with the previous method. The spectral data to be recovered are arranged in an adaptive pattern depending on the difficulty of recovery. In addition, according to the spectral characteristics, prior information associated with these spectral data is selectively transmitted that helps a neural network improve the performance of magnitude recovery. Prior information also provides the signs of recovered magnitudes. A subjective performance evaluation shows that, for mono coding without window switching at 40 kbps, the proposed coding method provides better sound quality than the conventional method on average.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054409","adaptive structure;audio coding;autoencoder;convolutional neural network;spectral recovery","Performance evaluation;Audio coding;Two dimensional displays;Switches;Signal processing;MONOS devices;Speech processing","adaptive signal processing;audio coding;convolutional neural nets;transforms","audio coding method;CNN-based spectral recovery;transform-based audio coding;spectral data;adaptive pattern;mono coding;neural network","","","","21","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A scalable to lossless audio streaming system applicable to mobile devices","D. Wu; J. Chen; X. Bao","Signal Processing Department, Institute for Infocomm Research, Fusionopolis, Singapore 138632; Signal Processing Department, Institute for Infocomm Research, Fusionopolis, Singapore 138632; Signal Processing Department, Institute for Infocomm Research, Fusionopolis, Singapore 138632","2011 6th IEEE Conference on Industrial Electronics and Applications","4 Aug 2011","2011","","","646","650","In this paper, we introduce an innovative, scalable to lossless audio streaming system applicable to mobile platforms. In the system, bit streams in MPEG-4 Scalable to Lossless Coding (SLS) audio format are used and the scalability feature of SLS audio is fully utilized. In the streaming server, the conventional streaming process is enhanced by delivering data packets adaptively with the dynamics of real-time network bandwidth. In the streaming client, the directshow technology is exploited efficiently. The system is capable of acting as the platform paradigm of the next generation system of streaming high quality music to mobile devices.","2158-2297","978-1-4244-8756-1","10.1109/ICIEA.2011.5975666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975666","Audio Adaptive Streaming;MPEG-4;SLS;Scalable","Servers;Transform coding;Decoding;Bandwidth;Streaming media;Encoding;Media","audio coding;audio streaming;mobile handsets;video coding","lossless audio streaming system;mobile device;mobile platform;MPEG-4;lossless coding audio format;streaming server;streaming process;data packets;real-time network bandwidth;streaming client;next generation system;high quality music","","1","","14","","4 Aug 2011","","","IEEE","IEEE Conferences"
"A new audio steganography scheme based on location selection with enhanced security","P. Pathak; A. K. Chattopadhyay; A. Nag","Dept. of Computer Sc. & Engineering, Academy Of Technology, West Bengal, India; Dept. of Computer Sc. & Engineering, Academy Of Technology, West Bengal, India; Dept. of Information Technology, Academy Of Technology, West Bengal, India","2014 First International Conference on Automation, Control, Energy and Systems (ACES)","1 May 2014","2014","","","1","4","Steganography is the art and science of secret communication. In this paper a new scheme for digital audio steganography is presented where the bits of a secret message are embedded into the coefficients of a cover audio. Each secret bit is embedded into the selected position of a cover coefficient. The position for insertion of a secret bit is selected from the 0th (Least Significant Bit) to 7th LSB based on the upper three MSB (Most Significant Bit). This scheme provides high audio quality, robustness and lossless recovery from the cover Audio.","","978-1-4799-3894-0","10.1109/ACES.2014.6807979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6807979","Steganography;secret communicatio;digital audio;LSB","Encoding;Encryption;Decoding;Signal processing algorithms;Information security","security of data;steganography;telecommunication security","communication security;message security;digital audio quality;cover audio coefficient;information security;most significant bit;MSB;LSB;least significant bit;digital audio steganography scheme;location selection","","3","","6","","1 May 2014","","","IEEE","IEEE Conferences"
"Enhanced surveillance platform with low-power wireless audio sensor networks","Guotao Zhao; H. Ma; Y. Sun; H. Luo; Xufei Mao","Beijing Key Lab of Intelligent Telecomm. Software and Multimedia, Beijing University of Posts and Telecomm., 100876, China; Beijing Key Lab of Intelligent Telecomm. Software and Multimedia, Beijing University of Posts and Telecomm., 100876, China; Beijing Key Lab of Intelligent Telecomm. Software and Multimedia, Beijing University of Posts and Telecomm., 100876, China; Beijing Key Lab of Intelligent Telecomm. Software and Multimedia, Beijing University of Posts and Telecomm., 100876, China; Beijing Key Lab of Intelligent Telecomm. Software and Multimedia, Beijing University of Posts and Telecomm., 100876, China","2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks","18 Aug 2011","2011","","","1","9","Video surveillance system, which can provide real-time display of the monitored scene and video playback, has been employed in many areas including: commercial security, accident investigation, law enforcement and emergency response. However, audio which carries important information not available in video is usually not taken seriously and used effectively. In this paper, we develop an enhanced surveillance platform by introducing the low-power wireless audio sensor networks (WASNs). We can obtain more comprehensive and precise monitoring without the limitation of the line-of-sight and lighting condition. Moreover, this platform is designed and built for providing key support to varieties of applications. This article describes the platform architecture, including design, implementation, and performance. We describe the audio sensor platform which can deliver high-quality audio over sensor network by multi-hops with low power requirement. In addition, we present the multimedia synchronization mechanism in the heterogeneous network which is the foundation of applications in the proposed platform. Our experiments include an in-depth analysis of the bottlenecks within the platform as well as measurements for the various components.","","978-1-4577-0351-5","10.1109/WoWMoM.2011.5986188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5986188","audio visual synchronization;wireless audio sensor networks;surveillance","Synchronization;Surveillance;Streaming media;Cameras;Visualization;Multimedia communication","audio signal processing;video surveillance;wireless sensor networks","enhanced surveillance platform;low-power wireless audio sensor networks;video surveillance system;WASN;multimedia synchronization mechanism","","1","","21","","18 Aug 2011","","","IEEE","IEEE Conferences"
"Shape Control of Discrete Generalized Gaussian Distributions for Frequency-Domain Audio Coding","R. Sugiura; Y. Kamamoto; T. Moriya","NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Kanagawa, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Kanagawa, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Kanagawa, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","26 Nov 2019","2019","27","12","2234","2248","Entropy coding, which is an essential part of audio compression, is always required to manage the tradeoffs between compression efficiency and computational complexity, and the strategy to achieve them highly depends on the distributions of inputs. In this paper, we present a method of controlling them for enhancing the compression efficiency of Golomb-Rice (GR) encoding, one of the simplest entropy coding methods optimal for Laplacian distributions. We will show that the proposed invertible and low-complexity mapping of integers enables the GR encoding to assign nearly the optimal code length for a wider range of distributions, generalized Gaussian distributions, maintaining low computational cost. A simulation by random numbers reveals that the proposed coder based on this scheme works about 6 times faster than the state-of-the-art arithmetic coder for Gaussian-distributed integers maintaining the increase in relative redundancy around 2.6%, which is much lower than that of a conventional GR coder. Additionally, an application to a practical speech and audio coding scheme is presented, and an objective evaluation for real speech and audio signals confirms the advantages of the proposed method in compression. The method is expected to widen the capability of low-complexity entropy coding, providing us with more flexible codec designs.","2329-9304","","10.1109/TASLP.2019.2945843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861102","Audio compression;entropy coding;generalized gaussian distribution","Psychoacoustic models;Speech coding;Laplace equations;Computational modeling;Shape;Speech processing","audio coding;codecs;computational complexity;frequency-domain analysis;Gaussian distribution;speech coding","codec designs;audio coding;speech coding;discrete generalized Gaussian distributions;shape control;low-complexity entropy coding;audio signals;audio coding scheme;conventional GR coder;Gaussian-distributed integers;arithmetic coder;random numbers;optimal code length;GR encoding;Laplacian distributions;entropy coding;Golomb-Rice encoding;computational complexity;audio compression;frequency-domain audio coding","","","","48","CCBY","7 Oct 2019","","","IEEE","IEEE Journals"
"Robust and Transparent Audio Watermarking based on Spread Spectrum in Wavelet Domain","A. A. Attari; A. A. B. Shirazi","School of Electrical Engineering, Iran University of Science & Technology (IUST), Tehran, Iran; School of Electrical Engineering, Iran University of Science & Technology (IUST), Tehran, Iran","2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT)","20 May 2019","2019","","","366","370","This paper proposes a robust and blind audio watermarking scheme based on spread spectrum in Discrete Wavelet Transform (DWT) domain. For this purpose, the watermarks are embedded in low-frequency coefficients, which are less audible. The main aim is to divide the audio signal into small frames and modify the magnitude of the 6<sup>th</sup> level approximation coefficients of DWT using the direct sequence spread spectrum (DSSS) technique. In addition, psychoacoustic model is used for enhancing in imperceptibility, and Savitsky-Golay filter is employed for increasing the extraction accuracy. The experimental results confirm high robustness against the most common attacks, including, re-sampling, requantizing, Gaussian noise addition MP3 compression, and low pass filter without significant perceptual distortion (ODG is higher than-1). The proposed scheme's data payload is about 83 bps.","","978-1-5386-7942-5","10.1109/JEEIT.2019.8717415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717415","Audio watermarking;Spread spectrum;Discrete wavelet transform;Psychoacoustic;Savitsky-Golayfilter","Watermarking;Robustness;Discrete wavelet transforms;Signal to noise ratio;Psychoacoustic models;Low pass filters;Digital audio players","audio coding;audio signal processing;audio watermarking;discrete wavelet transforms;Gaussian noise;low-pass filters;spread spectrum communication","low-frequency coefficients;audio signal;direct sequence spread spectrum technique;Savitsky-Golay filter;Gaussian noise addition MP3 compression;blind audio watermarking scheme;discrete wavelet transform domain;data payload;approximation coefficients;extraction accuracy;low-pass filter","","1","","15","","20 May 2019","","","IEEE","IEEE Conferences"
"A secure audio watermarking employing AES technique","U. R. Nair; G. K. Birajdar","Dept. of Electronics & Telecommunication Engineering, Pillai HOC College of Engineering and Technology, Raigad, Maharashtra, India, 410206; Dept. of Electronics and Telecommunication Engineering, Pillai HOC College of Engineering and Technology, Raigad, Maharashtra, India, 410206","2016 International Conference on Inventive Computation Technologies (ICICT)","26 Jan 2017","2016","3","","1","5","Innovative developments in computer technology has made distribution of data easier. But it has also put forth a new challenge to secure these multimedia data from privacy. In any kind of information system, data security and confidentiality services are generally required. In this paper we present a new secure audio watermarking technique based on Fast Fourier Transform (FFT) along with encryption. It combines Advanced Encryption Standard (AES) algorithm and a blind audio watermarking technique based on FFT along with Fibonacci numbers. Combining the encryption and watermarking algorithm enhances the security of watermark. The performance of this scheme is calculated using signal to noise ratio and bit error rate. Results indicate that the method is not only secure but also robust against various signal processing attacks with high imperceptibility.","","978-1-5090-1285-5","10.1109/INVENTIVE.2016.7830133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830133","Advanced Encryption Standard (AES);audio watermarking;Fast Fourier Transform;information security","Watermarking;Robustness;Encryption;Signal to noise ratio;Time-domain analysis;Frequency-domain analysis","audio watermarking;cryptography;fast Fourier transforms","secure audio watermarking;AES technique;advanced encryption standard;computer technology;data distribution;data security service;data confidentiality service;fast Fourier transform;FFT;blind audio watermarking technique;Fibonacci numbers;watermark security;signal-to-noise ratio;bit error rate;signal processing attacks","","1","","14","","26 Jan 2017","","","IEEE","IEEE Conferences"
"Robust Audio-Visual Speech Recognition System based on Gabor Features and Dynamic Stream Weight Adaption","A. Saudi; M. I. Khalil; H. Abbas","Digital Media Engineering and Technology Department, German University in Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt; Computer and Systems Engineering Department, Ain Shams University, Cairo, Egypt","2018 13th International Conference on Computer Engineering and Systems (ICCES)","14 Feb 2019","2018","","","399","403","This paper aims to enhance the performance of audio-visual speech recognition (AVSR) systems by introducing contributions in both the front-end and back-end system stages. Identifying a reliable feature is a crucial step towards enhancing the front-end stage of both audio-module and visual-module. A two-dimensional Gabor filter with different scales and directions is utilized to generate a set of noise robust spectro-temporal audio and visual features. The performance achieved from the Gabor audio features (GAFs) and Gabor visual features (GVFs) is compared to the performance of the traditional audio features such as MFCC, PLP, RASTA-PLP and visual features such as DCT2. The experimental results demonstrate that a system utilizes Gabor features in the front-end has a much better performance, especially at low SNR levels. To enhance the back-end stage, a framework based on synchronous multi-stream hidden Markov model is proposed to solve the dynamic stream weight estimation problem. To demonstrate the effect of dynamic weighting on enhancing the AVSR performance, we empirically compare between late integration (LI) and early integration (EI) strategies, especially in a low-SNR scenario. The experimental results show that the AVSR-LI system achieves superior performance for all SNR levels compared to AVSR-EI system.","","978-1-5386-5111-7","10.1109/ICCES.2018.8639475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639475","Audio-Visual Speech Recognition;Synchronous Multi-Stream Hidden Markov Model;Stream Weight","Visualization;Hidden Markov models;Signal to noise ratio;Speech recognition;Feature extraction;Adaptation models;Mel frequency cepstral coefficient","audio signal processing;computer vision;feature extraction;Gabor filters;hidden Markov models;speech recognition","Gabor audio features;dynamic stream weight estimation problem;dynamic weighting;AVSR performance;AVSR-LI system;AVSR-EI system;robust audio-visual speech recognition system;dynamic stream weight adaption;visual-module;two-dimensional Gabor filter;Gabor features;synchronous multistream hidden Markov model;noise robust spectro-temporal visual features;Gabor visual features;late integration strategy;early integration strategy;audio-module","","","","11","","14 Feb 2019","","","IEEE","IEEE Conferences"
"Research on audio bandwidth extension codec","L. Chuanhai; H. Ruimin; H. Bo; C. Sheng","National Engineering Research Center for Multimedia Software, Wuhan University, Wuhan, China; National Engineering Research Center for Multimedia Software, Wuhan University, Wuhan, China; National University of Defense Technology, Changsha, China; Hubei Telecom Technology Center, Wuhan, China","2013 3rd International Conference on Consumer Electronics, Communications and Networks","9 Jan 2014","2013","","","537","541","With stereo audio stepping into people's daily lives, spatial parametric technology comes to its broad prospects for development. This paper provides the audio bandwidth extension encoding and decoding devices, the bitrate of less high-frequency signal reconstruction, in order to improve the quality of the output audio signal. This research makes a contribution to the lack of existing technology, audio bandwidth extension encoding and decoding devices, digital audio decoding to take advantage of a lower bit rate to restore the original audio signal in the digital encoding process the loss of high-frequency components, thereby enhancing the sound playback quality.","","978-1-4799-2860-6","10.1109/CECNet.2013.6703388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703388","Stereo;Audio Bandwidth Extension;Complesity","Frequency-domain analysis;Frequency conversion;Bandwidth;Decoding;Encoding;Bit rate;Indexes","audio coding;codecs;signal reconstruction","audio bandwidth extension codec;stereo audio;encoding devices;decoding devices;signal reconstruction;digital audio decoding","","","","8","","9 Jan 2014","","","IEEE","IEEE Conferences"
"A new bandwidth extension technology for MPEG Unified Speech and Audio Coding","Y. Yamamoto; T. Chinen; M. Nishiguchi","Sony Corporation, Tokyo, Japan; Sony Corporation, Tokyo, Japan; Sony Corporation, Tokyo, Japan","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","523","527","In January 2012, MPEG finalized the new MPEG-D Unified Speech and Audio Coding (USAC) standard, which enables the coding of a variety of audio content at low bitrates. USAC provides low-bitrate coding by integrating a speech codec and an audio codec into a unified system. In USAC, Predictive Vector Coding (PVC) is added to Enhanced Spectral Band Replication (eSBR) to improve the subjective quality, especially for speech at low bitrates. For speech signals, there is generally a relatively high correlation between the spectral envelopes of low- and high-frequency bands. The PVC scheme exploits this by predicting the high-frequency envelopes from the low-frequency ones, with the coefficient matrices for the prediction being coded by means of vector quantization.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6637702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637702","Unified Speech and Audio Coding (USAC);Bandwidth extension;Predictive Vector Coding (PVC)","Speech;Hafnium;Bit rate;Speech coding;Vectors;MONOS devices;Multiple signal classification","audio coding;speech codecs;speech coding;vector quantisation;video coding","vector quantization;speech signals;eSBR;enhanced spectral band replication;PVC;predictive vector coding;audio codec;speech codec;low-bitrate coding;USAC standard;unified speech and audio coding;MPEG-D;bandwidth extension technology","","1","","10","","21 Oct 2013","","","IEEE","IEEE Conferences"
"3D audio coding approach based on spatial perception features","C. Yang; R. Hu; X. Wang; Y. Yang; M. Zhang; W. Chen","National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; School of Physics and Electronic Science, Guizhou Normal University, Guiyang, 550001, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University, Wuhan 430072, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; Collaborative Innovation Center of Geospatial Technology, Wuhan 430079, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China; National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan 430072, China","China Communications","22 Dec 2017","2017","14","11","126","140","A new three-dimensional (3D) audio coding approach is presented to improve the spatial perceptual quality of 3D audio. Different from other audio coding approaches, the distance side information is also quantified, and the non-uniform perceptual quantization is proposed based on the spatial perception features of the human auditory system, which is named as concentric spheres spatial quantization (CSSQ) method. Comparison results were presented, which showed that a better distance perceptual quality of 3D audio can be enhanced by 5.7%~8.8% through extracting and coding the distance side information comparing with the directional audio coding, and the bit rate of our coding method is decreased of 8.07% comparing with the spatial squeeze surround audio coding.","1673-5447","","10.1109/CC.2017.8233656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233656","3D audio coding;non-uniform perceptual quantization;distance perceptual quality","Three-dimensional displays;Audio coding;Feature extraction;Azimuth;Quantization (signal);Microphones","audio coding;quantisation (signal)","3D audio coding approach;spatial perception features;three-dimensional audio coding approach;spatial perceptual quality;nonuniform perceptual quantization;human auditory system;concentric spheres spatial quantization method;distance perceptual quality;distance side information comparing;directional audio coding;coding method;spatial squeeze surround audio coding","","","","","","22 Dec 2017","","","IEEE","IEEE Magazines"
"Research and Development of the Algorithm of Mixing Audio Data Streams for Heterogeneous Computer Systems in Telecommunications","Y. A. Kropotov; A. A. Kolpakov","Department of Electronics and Computer Science Murom Institute (branch), ""Vladimir State University named after Alexander and Nicholay Stoletovs"" VlSU, Murom, Russia; Department of Electronics and Computer Science Murom Institute (branch), ""Vladimir State University named after Alexander and Nicholay Stoletovs"" VlSU, Murom, Russia","2018 Dynamics of Systems, Mechanisms and Machines (Dynamics)","6 Jan 2019","2018","","","1","4","This paper presents an algorithm enhanced mixing of audio streams for computation on GPUs, which combines multiple stages of mixing by using two-pass rendering, which significantly reduces the switching time between buffers. Methods of computer experimental comparative studies were carried out evaluating the performance of the developed algorithm. The purpose of the present paper is development of an efficient algorithm for mixing audio streams for processing on GPUs. The method of transfer operations computing on graphics processors with the use of Shader programs was developed. Novel features presented solutions is using a two-pass rendering. The results showed that the application of the developed algorithm leads to an increase in computational performance up to 6 times. Presented solution can be implemented as software in the telecommunications multiprocessor systems.","","978-1-5386-5941-0","10.1109/Dynamics.2018.8601424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601424","two-pass rendering;algorithm for increasing productivity;parallel computing;heterogeneous computing systems;graphics processors;mixing of audio data","Graphics processing units;Heuristic algorithms;Three-dimensional displays;Rendering (computer graphics);Solid modeling;Attenuation","audio signal processing;audio streaming;graphics processing units;rendering (computer graphics)","heterogeneous computer systems;algorithm enhanced mixing;GPUs;two-pass rendering;computer experimental comparative studies;computational performance;switching time reduction;audio data stream mixing;telecommunication multiprocessor systems;graphics processors;Shader programs","","","","10","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Enhanced Data Hiding Audio Steganography Using Signal Ramping","S. N. Choudhury","Department of Computer Science & Engineering, RCCIIT, Kolkata, India","2018 Fourth International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)","23 May 2019","2018","","","258","263","The strength of steganography lies in the context of finding a challenge data value to be replaced. The order of occurrences of such data must also be kept as aperiodic. This paper introduces an approach of embedding the user information into the audio signal to have a better control over the message hiding and message security by removing the vulnerability issues like low robustness and ease of prediction of Least Significant Bit modification scheme with maximum signal alteration present in a data and randomness.","","978-1-5386-7638-7","10.1109/ICRCICN.2018.8718727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718727","Steganography;Cryptography;HAS;LSB;Ramp","Frequency diversity;Cryptography;Image edge detection;Robustness;Prediction algorithms;Frequency-domain analysis","audio coding;message authentication;steganography","enhanced data hiding audio steganography;signal ramping;user information;audio signal;message hiding;message security;signal alteration;vulnerability issues;least significant bit modification;low robustness issue","","","","19","","23 May 2019","","","IEEE","IEEE Conferences"
"SVD-Based Adaptive QIM Watermarking on Stereo Audio Signals","M. Hwang; J. Lee; M. Lee; H. Kang","Department of Electrical and Electronics, Yonsei University, Seoul, South Korea; Department of Electrical and Electronics, Yonsei University, Seoul, South Korea; Electronics and Telecommunications Research Institute, Daejeon, South Korea; Department of Electrical and Electronics, Yonsei University, Seoul, South Korea","IEEE Transactions on Multimedia","14 Dec 2017","2018","20","1","45","54","This paper proposes a blind digital audio water- marking algorithm that utilizes the quantization index modulation (QIM) and the singular value decomposition (SVD) of stereo audio signals. Conventional SVD-based blind audio watermarking algorithms lack physical interpretation since the matrix construction method for the input matrix for SVD is heuristically defined. However, in the proposed approach, because the SVD is directly applied to the stereo input signals, the resulting decomposed elements convey a conceptually meaningful inter- pretation of the original audio signal. As the proposed approach effectively utilizes the ratio of singular values, the embedded watermark is highly imperceptible and robust against volumetric scaling attacks; most QIM-based watermarking schemes are weak to these types of attacks. Experimental results under well-known practical attacks, such as compressions, resampling, and various types of signal processing, confirm that the proposed algorithm performs well compared to conventional audio watermarking algorithms.","1941-0077","","10.1109/TMM.2017.2721642","Electronics and Telecommunications Research Institute; Korean Government(grant numbers:15ZR1200); The Development of Active Audioprint Technology to Enhance the Media Usage; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962215","Audio watermarking;blind;data hiding;singular value decomposition (SVD);quantization index modulation (QIM);stereo","Watermarking;Robustness;Signal processing algorithms;Matrix decomposition;Quantization (signal);Frequency-domain analysis;Indexes","audio signal processing;audio watermarking;quantisation (signal);singular value decomposition","blind digital audio water-marking algorithm;SVD-based adaptive QIM watermarking;signal processing;QIM-based watermarking schemes;embedded watermark;stereo input signals;input matrix;matrix construction method;blind audio watermarking algorithms;singular value decomposition;quantization index modulation;stereo audio signals","","13","","38","Traditional","29 Jun 2017","","","IEEE","IEEE Journals"
"A new approach for secure data transfer in audio signals using DWT","B. Geethavani; E. V. Prasad; R. Roopa","Dept of CSE, Chadalawada Ramanama Engineering College, Tirupati, A.P, India; Dept of CSE, JNT University, Kakinada, A.P, India; Dept of CSE, Chadalawada Ramanama Engineering College, Tirupati, A.P, India","2013 15th International Conference on Advanced Computing Technologies (ICACT)","16 Jan 2014","2013","","","1","6","Steganography is an information hiding technique where secret message is embedded into unsuspicious cover signal. In this paper, a novel approach of integrating the features of cryptography and audio Steganography is presented. The information to be transmitted is encrypted by using modified blowfish algorithm and resultant cipher text is embedded into a cover audio file using discrete wavelet transform (DWT). The resultant stego audio is transmitted to the receiver and the reverse process is done in order to get back the original plain text. The proposed method presents a steganographic scheme along with the cryptographic scheme which enhances the security of the algorithm.","","978-1-4673-2818-0","10.1109/ICACT.2013.6710492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710492","Blowfish;Cryptography;Security;Audio steganography;Wavelets;DWT","Discrete wavelet transforms;Ciphers;Digital filters;PSNR","audio signal processing;cryptography;discrete wavelet transforms;steganography","secure data transfer;audio signals;DWT;information hiding technique;secret message;audio steganography;cryptography;modified blowfish algorithm;resultant cipher text;cover audio file;discrete wavelet transform;steganographic scheme;cryptographic scheme","","3","","17","","16 Jan 2014","","","IEEE","IEEE Conferences"
"Audio sub word sorter unit on merger sorter network for secure transmission","G. V. Bansod","Department of Electronics and Telecommunication, Symbiosis Institute of Technology, Pune, India","2011 IEEE International Conference on Control System, Computing and Engineering","26 Apr 2012","2011","","","127","131","Low power applications are major concern area nowadays. One of the major aspects is cryptography which includes software cryptography in audio as well as video applications. Many algorithms are developed to achieve software cryptography. But in recent year's algorithm are proved to be more efficient. This paper aims to enhance characteristics of HDL based implementation of GRP algorithm. As GRP algorithm is most attractive in term of sorting and cryptographic contents [8]. In this paper low power HDL based design is implemented for audio based applications with much more less power without losing encryption standards as compared to previous algorithms like EMSN[1]. This paper proposes a new algorithm REMS which is rich in encryption standards and consumes much more less power.","","978-1-4577-1642-3","10.1109/ICCSCE.2011.6190509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190509","Cryptography;Audio subword;HDL;low power;Permutation","Algorithm design and analysis;Encryption;Multiplexing;Sorting;Conferences;Hardware","audio signal processing;cryptography;sorting","audio subword sorter unit;merger sorter network;secure transmission;low power application;software cryptography;audio application;video application;HDL based implementation;GRP algorithm;sorting;cryptographic content;low power HDL based design;encryption standard;REMS algorithm","","","","9","","26 Apr 2012","","","IEEE","IEEE Conferences"
"A high capacity blind watermarking for two-channel audio signals based on CDMA-ICA","M. Khalil; A. El Bahi; A. Adib","LIM@II-FSTM, B.P. 146 Mohammedia 20650, Morocco; LIM@II-FSTM, B.P. 146 Mohammedia 20650, Morocco; LIM@II-FSTM, B.P. 146 Mohammedia 20650, Morocco","21st European Signal Processing Conference (EUSIPCO 2013)","8 May 2014","2013","","","1","5","In this paper, we investigate how data embedding capacity and extraction fidelity can be enhanced keeping imperceptibility of the host audio unaltered. To meet this end, we propose a new blind watermarking system for two-channel audio signals which is based on Code Division Multiple Access (CDMA) and Independent Components Analysis (ICA) techniques. At the emitter, CDMA is used to increase the watermark bit rate by inserting multiple parallel data. At the receiver, ICA algorithm is applied to recover the embedded information. In order to demonstrate the effectiveness of the proposed scheme, simulations under various conditions are conducted. The new system provides an embedding rate up to 60Kbits/s, while ensuring a compromise between inaudibility and extraction reliability.","2076-1465","978-0-9928626-0-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811792","Audio watermarking;High capacity;two-channel audio signals;CDMA;ICA","Watermarking;Multiaccess communication;Bit rate;Robustness;Bit error rate;Receivers;Instruments","audio watermarking;code division multiple access;independent component analysis","high capacity blind watermarking system;two-channel audio signals;CDMA-ICA algorithm;data embedding capacity;data embedding extraction fidelity;code division multiple access;independent components analysis techniques;multiple parallel data","","1","","9","","8 May 2014","","","IEEE","IEEE Conferences"
"Object-Based Audio for Live TV Production","S. A. Silva","21st Century Fox, USA","SMPTE 2015 Annual Technical Conference and Exhibition","8 Feb 2016","2015","","","1","9","Object-Based Audio (OBA) is the next breakthrough in live television production. It will provide an enhanced listening experience and personalization as revolutionary as sound was to motion pictures in the 1930's. The age of personalization has arrived and TV consumers can view any program, at any time and on virtually any media device. ‚Äî The next generation of audio encoders will have the capabilities to create OBA in live television production and post-production. Features of OBA include audio personalization for language selection, dialogue enhancements and options for the hearing impaired. OBA will provide the viewer with the ability to customize their viewing for any type of program in any viewing setting. ‚Äî The future audio codec technologies will enable the creative chain to produce customized audio for the viewer. This process begins at the original mix location and continues through the broadcast chain to any consumer device. These encoders will have the capability to emit surround sound and immersive sound with objects either separately or in combination with each other. Scene based audio will also be a feature of the next generation codecs enabling the mixer to represent the sound image instead of channels.","","978-1-61482-956-0","10.5594/M001650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399638","Object-Based Audio(OBA);immersive sound;next generation audio encoder;objects;live production TV;personalization;enhanced listening;audio codecs;metadata","","","","","1","","7","","8 Feb 2016","","","SMPTE","SMPTE Conferences"
"Recipes for Creating and Delivering Next-Generation Broadcast Audio","S. Mehta; T. Onders; J. Riedmiller",NA; NA; NA,"SMPTE Motion Imaging Journal","2 Jan 2017","2016","125","9","25","32","Next-generation audio systems and codecs allow content creators to engage their audiences with more accessible, immersive, and personalized sound experiences. While these systems provide a great deal of flexibility in the amount of audio that can be delivered and the amount of control given to consumers, the industry can benefit from a set of predefined operating profiles for the first incarnations of next-generation audio. This paper provides a practical overview of some basic audio profiles and mechanisms for delivering stereo, surround, personalized, and immersive content in next-generation audio systems. Legacy stereo and surround content benefits from new system features, including enhanced loudness management and improved dialogue intelligibility for premixed sources. Personalized and immersive content can be created and delivered in ways that ensure that every consumer receives a premium experience across every device. New delivery systems and encoders ensure seamless and robust switching between different content types and layouts.","2160-2492","","10.5594/JMI.2016.2619304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803442","AC-4;accessible audio;audio mixing;audio objects;dialogue enhancement;dolby;dolby Atmos;immersive audio;loudness;next-generation audio;object-based audio;personalization;personalized audio;three-dimensional (3D) audio","","","","","","","4","","2 Jan 2017","","","SMPTE","SMPTE Journals"
"Modified video watermarking scheme using audio silence deletion","M. Charfeddine; E. Mezghani; C. Ben Amar","REGIM: REsearch Group on Intelligent Machines, University of Sfax, National School of Engineers (ENIS), BP 1173, Sfax, 3038, Tunisia; REGIM: REsearch Group on Intelligent Machines, University of Sfax, National School of Engineers (ENIS), BP 1173, Sfax, 3038, Tunisia; REGIM: REsearch Group on Intelligent Machines, University of Sfax, National School of Engineers (ENIS), BP 1173, Sfax, 3038, Tunisia","Proceedings ELMAR-2013","11 Nov 2013","2013","","","203","206","Most of classic video watermarking techniques operate only on the visual flow to embed the watermark. That's why, in this work, we propose to improve those schemes and to enhance the embedding capacity by using also the sound stream to bury the watermark. So, in this paper, we focus on the audio flow and we present a modified audio watermarking technique robust to MP3 compression and adapted to be applied to the sound stream of digital video exposed to MPEG compression. In fact, we exploit a classic audio watermarking technique by applying it to digital video. However, the extraction of the embedded watermark became impossible after MPEG compression since the video compression contributes in some cases to add a shifting in the audio stream. That's why, we propose to add silence deletion blocks into the classic watermarking scheme in order to guarantee the robustness of the watermarked video to MPEG compression. So, we present in this paper the modified audio watermarking scheme applied to digital video and we expose the corresponding results.","1334-2630","978-953-7044-14-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658352","Audio watermarking;Video watermarking;silence detection;MPEG compression","Watermarking;Transform coding;Digital audio players;Robustness;Streaming media;Signal to noise ratio;Visualization","data compression;video watermarking","modified video watermarking scheme;audio silence deletion;embedding capacity;sound stream;audio watermarking technique;MP3 compression;digital video;MPEG compression;audio stream","","","","7","","11 Nov 2013","","","IEEE","IEEE Conferences"
"Audio Effect Units in Mobile Devices for Electric Musical Instruments","S. Yao","Department of Electrical Engineering, National Taipei University, New Taipei City, Taiwan","IEEE Access","8 Nov 2019","2019","7","","159239","159250","With the advent of modern techniques, there has been an increase in mobile devices with powerful functions. This study aims to utilize application software instead of hardware equipment to alter the sound of electric musical instruments by developing the functions of audio effect units on a mobile device. The built-in software audio effects include dynamic effects, delay effects, mixing, and equalization. Multichannel audio signal processing is proposed to enhance sound externalization. The listening tests indicate that the sound effects together with a quadraphonic system produce superior special effects and spatial audio than conventional effect units. Additionally, a denoiser is proposed for noise reduction, which is a function especially helpful for singers performing on busy streets. The customization in the module is achieved by a personal voice preprocessing system. A dual-filter function was utilized for the denoiser to adjust to different environments. The objective performance measurements demonstrate that the proposed denoiser outperforms the state-of-the-art methods. A hardware audio interface serving as the connection between a mobile device and an electric instrument, such as an electric guitar, electric piano, or electric bass, was also built, providing impedance matching and voltage balance. The proposed interface transfers the electric instrument signal into a 3.5-mm jack in a smartphone or tablet. The developed audio interface is light and low-noise and can operate without being connected to an external power supply, thereby making it suitable for street musicians. The experiments validate the feasibility of using the proposed circuit for real-time audio signal conversion.","2169-3536","","10.1109/ACCESS.2019.2950780","Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2221-E-305-010-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888258","Audio effects;electric bass;electric guitar;multichannel audio;noise reduction","Loudspeakers;Mobile handsets;Instruments;Software;Delay effects;Reverberation;Mixers","audio signal processing;impedance matching;mobile radio;musical instruments;signal denoising","external power supply;voltage balance;impedance matching;quadraphonic system;electric musical instruments;real-time audio signal conversion;audio interface;electric instrument signal;electric bass;electric piano;electric guitar;hardware audio interface;dual-filter function;sound externalization;multichannel audio signal processing;software audio effects;mobile device;audio effect units","","","","23","CCBY","31 Oct 2019","","","IEEE","IEEE Journals"
"Methods for enhanced harmonic transposition","L. Villemoes; P. Ekstrand; P. Hedelin","Dolby Sweden AB, G√§vlegatan 12A, 113 30 Stockholm, Sweden; Dolby Sweden AB, G√§vlegatan 12A, 113 30 Stockholm, Sweden; Dolby Sweden AB, G√§vlegatan 12A, 113 30 Stockholm, Sweden","2011 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","17 Nov 2011","2011","","","161","164","In systems for High Frequency Reconstruction (HFR) employing harmonic transposition, there is a risk of introducing artifacts due to conflicting design goals for stationary, transient, and periodic signals. We describe a filter bank implementation of the transposer which addresses this problem by window design, frequency domain oversampling, and cross products.","1947-1629","978-1-4577-0693-6","10.1109/ASPAA.2011.6082282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6082282","harmonic transposition;harmonic bandwidth extension;high frequency reconstruction;phase vocoder;audio coding","Harmonic analysis;Power harmonic filters;Filter banks;Vocoders;Audio coding;Time frequency analysis","filtering theory;frequency-domain analysis;harmonic analysis;signal reconstruction;signal sampling","enhanced harmonic transposition;high frequency reconstruction;periodic signal;filter bank implementation;window design;frequency domain oversampling","","1","1","8","","17 Nov 2011","","","IEEE","IEEE Conferences"
"Joint Adaptive Impulse Response Estimation and Inverse Filtering for Enhancing In-Car Audio","A. Dagar; S. S. Nitish; R. Hegde","Indian Institute of Technology Kanpur, India; Indian Institute of Technology Kanpur, India; Indian Institute of Technology Kanpur, India","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","416","420","Performance of conventional audio equalization methods for improving in-car audio listening experience is limited by the uncertainties in computing the highly varying in-car channel response. Hence these methods generally compute the channel response which is then utilized in designing the inverse filter. In this paper, a novel adaptive equalization method is developed where the channel impulse response and inverse filter are jointly estimated. The method iteratively estimates the uncertainties in the channel response using a Kalman filter and updates the inverse filter gains at every step. The joint estimation method is thus adaptive and robust to the highly varying in-car acoustic conditions. Additional contributions of this work include the development of a car database that captures impulse responses and noise samples under various in-car conditions. Both subjective and objective evaluations are performed to show the performance improvements obtained using the proposed method.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462329","adaptive equalization;car acoustics;inverse filtering;audio enhancement","Automobiles;Acoustics;Adaptive equalizers;Loudspeakers;Estimation;Channel estimation;Kalman filters","adaptive equalisers;audio equipment;audio systems;iterative methods;Kalman filters;transient response","channel impulse response;joint estimation method;in-car acoustic conditions;car database;impulse responses;in-car conditions;joint adaptive impulse response estimation;inverse filtering;in-car audio listening experience;in-car channel response;novel adaptive equalization method;Kalman Filter;audio equalization methods","","","","20","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Enhancing effectiveness and reducing time of system validation for Interactive Multimedia LED TV","P. Markande; P. V. Joshi; S. S. Manvi","Reva Institute of Technology and Management, Electronics and Communication Department, Bangalore, India; Reva Institute of Technology and Management, Electronics and Communication Department, Bangalore, India; Reva Institute of Technology and Management, Electronics and Communication Department, Bangalore, India","2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","21 Oct 2013","2013","","","1738","1743","This work mainly focuses on automating validation of functionalities in complex LED TVs to overcome manual validation difficulties. Validation of the system which consists of functionalities of LED TV set is in the focus. An audio verification method was also developed and this is currently being deployed at TPVision (Previously Philips TV) for test automation of audio verification in Interactive Multimedia LED TVs. The method is computationally efficient, scalable and capable of quickly performing audio compare on audio captured through a LED TV in the presence of foreground voices and other dominant noise. It can verify any format of audio, be it .mp3, .mp4, .wav, AC-3 or Dolby Digital sound signals, etc. This task is performed using MATLAB and later built into standalone application, which is successfully integrated into existing test automation environment. This work helps to reduce the time required in validation and also to enhance audio validation efficiency and reduce time for the same in test automation process to come up with better working product.","","978-1-4673-6217-7","10.1109/ICACCI.2013.6637443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637443","Automated validations;Functional verification;Image comparison;Audio compare;Test automation;LED TV;Audio verification","Automation;TV;Testing;Light emitting diodes;Software;Manuals;Hardware","audio signal processing;automatic testing;interactive television;LED displays;multimedia systems","system validation effectiveness enhancement;system validation time reduction;interactive multimedia LED TV;automatic functionality validation;audio verification method;TPVision;Philips TV;foreground voices;.mp3 audio format;.mp4 audio format;.wav audio format;AC-3 audio format;Dolby Digital sound signals;Matlab;standalone application;test automation environment;audio validation efficiency enhancement","","1","","30","","21 Oct 2013","","","IEEE","IEEE Conferences"
"Hierarchical Model For Long-Length Video Summarization With Adversarially Enhanced Audio/Visual Features","H. Lee; G. Lee","Seoul National University of Science and Technology,Republic of Korea; Seoul National University of Science and Technology,Republic of Korea","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","723","727","In this paper, we propose a novel supervised method for summarizing long-length videos. Many recent approaches presented promising results in video summarization. However, videos in most benchmark datasets are short in duration (<; 10 minutes), and the methods often do not work well for very long-length videos (>1 hour). Furthermore, most approaches only use visual features, while audios provide useful information for the task. Based on these observations, we present a model that exploits both audio and visual features. To handle long videos, the hierarchical structure of our model captures both the short-term and long-term temporal dependencies. Our model also refines the extracted features using adversarial networks. To demonstrate our model, we have collected a new dataset of 28 baseball (~3.5 hours) videos, accompanied by an editorial summary video that is 5% in length of the original video. Evaluation on the dataset suggests that our method produces quality summaries for very long videos.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190636","video summarization;multimodal features;hierarchical model;adversarial learning;long-length videos","Visualization;Feature extraction;Semantics;Benchmark testing;Task analysis;Generators","audio-visual systems;feature extraction;neural nets;sport;video signal processing","hierarchical model;long-length video summarization;novel supervised method;benchmark datasets;hierarchical structure;long-term temporal dependencies;baseball videos;editorial summary video;adversarially enhanced audio-visual features;short-term temporal dependencies;adversarial networks;feature extraction;time 10.0 min;time 1.0 hour;time 3.5 hour","","","","15","","30 Sep 2020","","","IEEE","IEEE Conferences"
